{
    "collab_server" : "",
    "contents" : "date = Sys.Date()-1\ndate.str = format(date,'%Y%m%d')\nspec.date.str = \"20171112\"\npickedColums = c(\"max_stay\",\"min_stay\",\"avg_stay\",\"pv\",\"umid_count_same_ip\",\"sign\",\"city_perc\",\"md_perc\")\n\ncalf1 = function(real,pred){\naccuracy = sum(real==pred)/length(real)\n#precise定义为当你认为是真时，实际是真的比例\nprecise = sum(real==1&pred==1)/sum(pred==1)\n#spec定义为实际是假时，你也认为是假的比例\nspec = sum(real==0&pred==0)/sum(real==0)\n#当实际是真时，你也认为是真的比例recall/sensitivity\nrecall=sens = sum(real==1&pred==1)/sum(real==1)\nf1 = 2*precise*recall/(precise+recall)\nreturn(list(f1=f1,accuracy = accuracy,precise = precise,recall = recall))\n  }\n\ncalAUC = function(real,pred){\n  library(AUC)\n  test_roc = roc(pred,real)\n  test_auc = auc(test_roc)\n  return(test_auc)\n}\nsource('~/Rfile/R_impala.R')\n\ncity_sql = paste0(\"select x.*,x.city_count_new/x.city_count_all city_perc from\n(select m.l_city,m.dt,count(*) city_count_all,count(if(m.isnew = 'new','new',NULL)) city_count_new from \n(select i.*,case when (regexp_replace(to_date(firstonlinetime),'-','')) = i.dt then 'new' else 'old' end isnew \nfrom dm.dm_app_pageview_info i inner join dl.umid_firstonlinetime f on i.u_mid = f.u_mid\nwhere f.dt = '\",spec.date.str,\"') m group by m.l_city,m.dt) x\")\n\nmodel_sql = paste0(\"select x.*,x.md_count_new/x.md_count_all md_perc from\n(select m.d_model,m.dt,count(*) md_count_all,count(if(m.isnew = 'new','new',NULL)) md_count_new from \n(select i.*,case when (regexp_replace(to_date(firstonlinetime),'-','')) = i.dt then 'new' else 'old' end isnew \nfrom dm.dm_app_pageview_info i inner join dl.umid_firstonlinetime f on i.u_mid = f.u_mid\nwhere f.dt = '\",spec.date.str,\"') m group by m.d_model,m.dt) x\")\n\numid_sql = \"select u_mid from test.train_sample\"\n\numid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in ('漯河','漯河市','luohe') and dt = '20171203' and path = 'z'\"\n\nspec.date.str = \"20171203\"\n\nbase_sql = paste0(\"select base.*,umid_count_same_ip from \n(select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n  from dm.dm_app_pageview_info where u_mid in (\",umid_sql,\") and dt <= '\",spec.date.str,\"' and path = 'z'\n  group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info where u_mid in \n                                       (\",umid_sql,\") \n                                       and dt <= '\",spec.date.str,\"' and path = 'z' group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n\ncheck_sql = \"select * from test.train_sample\"\n\n\n\nbase = read_data_impala_general(base_sql)\nmodel = read_data_impala_general(model_sql)\ncity = read_data_impala_general(city_sql)\ncheck = read_data_impala_general(check_sql)\n#ip = read_data_impala_general(ip_sql)\n\nbase$sign = ifelse(base$umid_count_same_ip<20,0,1)\nbase_city = merge(base,city[city$dt == spec.date.str,],by.x = \"l_city\",by.y = \"l_city\",all.x = TRUE)\nbase_city_model = merge(base_city,model[model$dt == spec.date.str,],by.x = \"d_model\",by.y = \"d_model\",all.x = TRUE)\n\ntrain_set = base_city_model[,pickedColums]\nx = train_set[,!(names(train_set) %in% \"sign\")]\ntrain_set$sign = as.factor(train_set$sign)\ny = train_set$sign\none_sample_train_set = train_set[train_set$sign == \"1\",]\n# library(mice)\n# md.pattern(x)\n# View(x[is.na(x)])\n\n#This can't handle the missing value part\nlibrary(caret)\nlibrary(klaR)\nmodel = train(x,y,'nb',trControl=trainControl(method='cv',number=10))\nresult = predict(model$finalModel,x)\n\nlibrary(naivebayes)\nmodel_nb = naive_bayes(sign~.,train_set)\nresult_nb = predict(model_nb,x)\nnb_list = calf1(y,result_nb)\nnb_f1 = nb_list$f1\nnb_AUC = calAUC(y,result_nb)\n\nlibrary(randomForest)\nmodel_random_forest = randomForest(sign~.,train_set[complete.cases(train_set),])\nresult_random_forest = predict(model_random_forest,train_set[complete.cases(train_set),!(names(train_set) %in% \"sign\")])\nrf_list = calf1(train_set[complete.cases(train_set),]$sign,result_random_forest)\nrf_AUC = calAUC(train_set[complete.cases(train_set),]$sign,result_random_forest)\n\nlibrary(e1071)\nmodel_svm = svm(sign~.,train_set)\nresult_svm = predict(model_svm,x)\nsvm_list = calf1(train_set[complete.cases(train_set),]$sign,result_svm)\nsvm_AUC = calAUC(train_set[complete.cases(train_set),]$sign,result_svm)\nsummary(model_svm)\n\n# library(EMCluster)\nlibrary(mclust)\nBIC <- mclustBIC(train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\"))])\nplot(BIC)\nsummary(BIC)\n\nICL = mclustICL(train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\"))])\nplot(ICL)\nsummary(ICL)\n#test EM\n# msEst <- mstep(modelName = \"EEE\", data = iris[,-5], \n#                z = unmap(iris[,5]))\n# names(msEst)\n# \n# result_em_iris = em(modelName = msEst$modelName, data = iris[,-5],\n#    parameters = msEst$parameters)\n\n# specificity(data = result,reference = ori_result)\n# sensitivity(data = result,reference = ori_result)\n#EEV\n#VII\n#The best for our company's data is VEV AUC:0.999093\ntrain_base = train_set[complete.cases(train_set),]\nset.seed(1000)\ntrain_index = sample(nrow(train_base),2/3*nrow(train_base))\ntrain_sample = train_base[train_index,]\ntest_sample = train_base[-train_index,]\n\nmEst = mstep(modelName = \"VEV\", data = train_sample[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],z = unmap(train_sample[,\"sign\"]))\nresult_em_user = em(modelName = mEst$modelName,data = test_sample[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],\n                    parameters = mEst$parameters)\nView(result_em_user$z)\nem_result = ifelse(result_em_user$z[,1]-result_em_user$z[,2]>0,0,1)\nem_list = calf1(test_sample[,\"sign\"],em_result)\nem_AUC = calAUC(test_sample[,\"sign\"],em_result)\n\ntest = read_data_impala_general(base_sql)\ntest$sign = 1\ntest_city = merge(test,city[city$dt == spec.date.str,],by.x = \"l_city\",by.y = \"l_city\",all.x = TRUE)\ntest_city_model = merge(test_city,model[model$dt == spec.date.str,],by.x = \"d_model\",by.y = \"d_model\",all.x = TRUE)\n\ntest_set = test_city_model[,pickedColums]\nx = test_set[,!(names(test_set) %in% \"sign\")]\ntest_set$sign = factor(test_set$sign,levels = c('0','1'))\ny = as.character(test_set$sign)\ntest_em_user = em(modelName = mEst$modelName,data = test_set[,!(names(test_set)%in%c(\"sign\",\"city_perc\",\"md_perc\"))],\n                    parameters = mEst$parameters)\nem_test_result = ifelse(test_em_user$z[,1]-test_em_user$z[,2]>0,0,1)\nem_test_list = calf1(y,em_test_result)\nem_test_AUC = calAUC(y,em_test_result)\n\nresult_nb = predict(model_nb,x)\nresult_nb = as.character(result_nb)\nnb_list = calf1(y,result_nb)\nnb_f1 = nb_list$f1\nnb_AUC = calAUC(y,result_nb)\n#draw a picture through cluster\nX = train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\",\"city_perc\"))]\nBIC <- mclustBIC(X,G=2) #We only need to consider the cases for 2 clusters\nplot(BIC)\nsummary(BIC)\nmod2 <- Mclust(X, x = BIC)\n# summary(mod2, parameters = TRUE)\nplot(mod2, what = \"classification\")\n#che\nclass = train_set[complete.cases(train_set),\"sign\"]\nclPairs(X, class)\n\n#VVV,EVV,VVE,VVI not correct\n\nmEst = mstep(modelName = \"VEV\", data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],z = unmap(train_set$sign))\nresult_em_user = em(modelName = mEst$modelName,data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],\n                    parameters = mEst$parameters)\nView(result_em_user$z)\n\nmEst = mstep(modelName = \"VEI\", data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],z = unmap(train_set$sign))\nresult_em_user = em(modelName = mEst$modelName,data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],\n                    parameters = mEst$parameters)\nView(result_em_user$z)\n\n# ip_sql = paste0(\"select x.*,x.ip_count_new/x.ip_count_all ip_perc from\n# (select m.l_ip,m.dt,count(*) ip_count_all,count(if(m.isnew = 'new','new',NULL)) ip_count_new from \n#                 (select i.*,case when (regexp_replace(to_date(firstonlinetime),'-','')) = i.dt then 'new' else 'old' end isnew from dm.dm_app_pageview_info i inner join dl.umid_firstonlinetime f on i.u_mid = f.u_mid\n#                 where f.dt = '\",spec.date.str,\"') m group by m.l_ip,m.dt) x\")\n\n\n# base_sql_qingyuan = paste0(\"select base.*,umid_count_same_ip from \n# (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n#                            from dm.dm_app_pageview_info where l_city in ('清远','清远市','qingyuan','qingyuanshi') and dt = '\",spec.date.str,\"' and path = 'z'\n#                            group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info where l_city in \n#                            ('清远','清远市','qingyuan','qingyuanshi') \n#                            and dt = '\",spec.date.str,\"' and path = 'z' group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n\n#using one sign classification from SVM\nlibrary(e1071)\nmodel_svm_one_sample = svm(sign~.,one_sample_train_set,type = \"one-classification\")\nresult_svm_one_sample = predict(model_svm_one_sample,x)\n#test if this can work for multiclass\nmodel_svm2 = svm(sign~.,train_set,type = \"one-classification\")\nresult_svm2 = predict(model_svm2,train_set)\n\ngetSrcDirectory(function(x) {x})\ntemp = dirname(rstudioapi::getActiveDocumentContext()$path)\nrstudioapi::getActiveDocumentContext()$path\n\n\n",
    "created" : 1512463601962.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "4275863167",
    "id" : "148CD4D4",
    "lastKnownWriteTime" : 1513319439,
    "last_content_update" : 1513319439,
    "path" : "~/R_Projects/abnormal_activity_analysis/Rfile/outdecider.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}