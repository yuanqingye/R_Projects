{
    "collab_server" : "",
    "contents" : "library(mlbench)\nlibrary(caret)\nlibrary(plyr)\ncal_model_accuracy = function(model,newset,keycol,calf,caltype)\n{\n  newset = newset[complete.cases(newset),]\n  model_result = predict(object = model,newdata = newset)\n  model_cal = calf(newset[,keycol],model_result,caltype)\n  return(model_cal)\n}\n\ngo_around_model = function(dataset,test_formula){\n  pbar <- create_progress_bar('text')\n  k = 11\n  pbar$init(k)\n  pbar$step()\n  test_formula = as.formula(test_formula)\n  control <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n  seed <- 7\n  metric <- \"Accuracy\"\n  preProcess=c(\"center\", \"scale\")\n  pbar$step()\n  #LDA\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.lda <- train(test_formula, data=dataset, method=\"lda\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  lda_time = proc.time() - ptm\n  # Logistic Regression\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.glm <- train(test_formula, data=dataset, method=\"glm\", metric=metric, trControl=control)\n  glm_time = proc.time() - ptm\n  # GLMNET\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.glmnet <- train(test_formula, data=dataset, method=\"glmnet\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  glmnet_time = proc.time() - ptm\n  # SVM Radial\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.svmRadial <- train(test_formula, data=dataset, method=\"svmRadial\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control, fit=FALSE)\n  svm_time = proc.time() - ptm\n  # kNN\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.knn <- train(test_formula, data=dataset, method=\"knn\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  knn_time = proc.time() - ptm\n  # Naive Bayes\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.nb <- train(test_formula, data=dataset, method=\"nb\", metric=metric, trControl=control)\n  nb_time = proc.time() - ptm\n  # CART\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.cart <- train(test_formula, data=dataset, method=\"rpart\", metric=metric, trControl=control)\n  cart_time = proc.time() - ptm\n  # C5.0\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.c50 <- train(test_formula, data=dataset, method=\"C5.0\", metric=metric, trControl=control)\n  c50_time = proc.time() - ptm\n  # Bagged CART\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.treebag <- train(test_formula, data=dataset, method=\"treebag\", metric=metric, trControl=control)\n  treebag_time = proc.time() - ptm\n  # Random Forest\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.rf <- train(test_formula, data=dataset, method=\"rf\", metric=metric, trControl=control)\n  rf_time = proc.time() - ptm\n  # Stochastic Gradient Boosting (Generalized Boosted Modeling)\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.gbm <- train(test_formula, data=dataset, method=\"gbm\", metric=metric, trControl=control, verbose=FALSE)\n  gbm_time = proc.time() - ptm\n  pbar$step()\n  results <- resamples(list(lda=fit.lda, logistic=fit.glm, glmnet=fit.glmnet,\n                            svm=fit.svmRadial, knn=fit.knn, nb=fit.nb, cart=fit.cart, c50=fit.c50,\n                            bagging=fit.treebag, rf=fit.rf, gbm=fit.gbm))\n  time_records = list(lda_time = lda_time,glm_time = glm_time,glmnet_time = glmnet_time,\n                      glmnet_time = glmnet_time,svm_time = svm_time,knn_time = knn_time,\n                      nb_time = nb_time,cart_time = cart_time,c50_time = c50_time,\n                      treebag_time = treebag_time,rf_time = rf_time,gbm_time = gbm_time)\n  return(list(results,time_records))\n  # summary(results)\n  # bwplot(results)\n}\n\ngo_around_model_with_test = function(dataset,newset,keycol,calf,caltype = \"accuracy\"){\n  pbar <- create_progress_bar('text')\n  k = 11\n  pbar$init(k)\n  pbar$step()\n  test_formula = paste0(keycol,\"~.\")\n  test_formula = as.formula(test_formula)\n  control <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\n  seed <- 7\n  metric <- \"Accuracy\"\n  preProcess=c(\"center\", \"scale\")\n  pbar$step()\n  #LDA\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.lda <- train(test_formula, data=dataset, method=\"lda\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  lda_cal = cal_model_accuracy(model = fit.lda,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  lda_time = proc.time() - ptm\n  # Logistic Regression\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.glm <- train(test_formula, data=dataset, method=\"glm\", metric=metric, trControl=control)\n  glm_cal = cal_model_accuracy(model = fit.glm,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  glm_time = proc.time() - ptm\n  # GLMNET\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.glmnet <- train(test_formula, data=dataset, method=\"glmnet\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  glmnet_cal = cal_model_accuracy(model = fit.glmnet,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  glmnet_time = proc.time() - ptm\n  # SVM Radial\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.svmRadial <- train(test_formula, data=dataset, method=\"svmRadial\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control, fit=FALSE)\n  svm_cal = cal_model_accuracy(model = fit.svmRadial,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  svm_time = proc.time() - ptm\n  # kNN\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.knn <- train(test_formula, data=dataset, method=\"knn\", metric=metric, preProc=c(\"center\", \"scale\"), trControl=control)\n  knn_cal = cal_model_accuracy(model = fit.knn,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  knn_time = proc.time() - ptm\n  # Naive Bayes\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.nb <- train(test_formula, data=dataset, method=\"nb\", metric=metric, trControl=control)\n  nb_cal = cal_model_accuracy(model = fit.nb,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  nb_time = proc.time() - ptm\n  # CART\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.cart <- train(test_formula, data=dataset, method=\"rpart\", metric=metric, trControl=control)\n  cart_cal = cal_model_accuracy(model = fit.cart,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  cart_time = proc.time() - ptm\n  # C5.0\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.c50 <- train(test_formula, data=dataset, method=\"C5.0\", metric=metric, trControl=control)\n  c50_cal = cal_model_accuracy(model = fit.c50,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  c50_time = proc.time() - ptm\n  # Bagged CART\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.treebag <- train(test_formula, data=dataset, method=\"treebag\", metric=metric, trControl=control)\n  treebag_cal = cal_model_accuracy(model = fit.treebag,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  treebag_time = proc.time() - ptm\n  # Random Forest\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.rf <- train(test_formula, data=dataset, method=\"rf\", metric=metric, trControl=control)\n  rf_cal = cal_model_accuracy(model = fit.rf,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  rf_time = proc.time() - ptm\n  # Stochastic Gradient Boosting (Generalized Boosted Modeling)\n  pbar$step()\n  set.seed(seed)\n  ptm <- proc.time()\n  fit.gbm <- train(test_formula, data=dataset, method=\"gbm\", metric=metric, trControl=control, verbose=FALSE)\n  gbm_cal = cal_model_accuracy(model = fit.gbm,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n  gbm_time = proc.time() - ptm\n  pbar$step()\n  results <- resamples(list(lda=fit.lda, logistic=fit.glm, glmnet=fit.glmnet,\n                            svm=fit.svmRadial, knn=fit.knn, nb=fit.nb, cart=fit.cart, c50=fit.c50,\n                            bagging=fit.treebag, rf=fit.rf, gbm=fit.gbm))\n  cal_results = list(lda_cal = lda_cal,glm_cal = glm_cal,\n                     glmnet_cal = glmnet_cal,svm_cal = svm_cal,knn_cal = knn_cal,\n                     nb_cal = nb_cal,cart_cal = cart_cal,c50_cal = c50_cal,\n                     treebag_cal = treebag_cal,rf_cal = rf_cal,gbm_cal = gbm_cal)\n  time_records = list(lda_time = lda_time,glm_time = glm_time,\n                      glmnet_time = glmnet_time,svm_time = svm_time,knn_time = knn_time,\n                      nb_time = nb_time,cart_time = cart_time,c50_time = c50_time,\n                      treebag_time = treebag_time,rf_time = rf_time,gbm_time = gbm_time)\n  return(list(results,cal_results,time_records))\n  # summary(results)\n  # bwplot(results)\n}\n\ngo_around_model_with_test_simple_version = function(dataset,newset,keycol,modeldf,\n  calf,caltype = \"accuracy\",metric = \"Accuracy\",preProc = c(\"center\",\"scale\")){\n  K = nrow(modeldf)\n  resample_list = list()\n  time_records = list()\n  cal_results = list()\n  test_formula = paste0(keycol,\"~.\")\n  test_formula = as.formula(test_formula)\n  pbar = create_progress_bar(\"text\")\n  pbar$init(K)\n  seed = 6\n  #when method=none then use entire set for training\n  trControl = trainControl(method = \"repeatedcv\",number = 10,repeats = 3)\n  for(md in modeldf[[1]]){\n    set.seed(seed)\n    ptm <- proc.time()\n    if(md %in% c(\"lda\",\"glmnet\",\"svmRadial\",\"knn\")){\n      tr_model = train(form = test_formula,data = dataset,method = md,metric = metric,trControl = trControl,preProc = preProc)\n    }\n    else if(md %in% c(\"gbm\")){\n      tr_model = train(form = test_formula,data = dataset,method = md,metric = metric,trControl = trControl,verbose = FALSE)\n    }\n    else{\n      tr_model = train(form = test_formula,data = dataset,method = md,metric = metric,trControl = trControl)\n    }\n    effect = cal_model_accuracy(model = tr_model,newset = newset,keycol = keycol,calf = calf,caltype = caltype)\n    resample_list[[md]] = tr_model\n    cal_results[[md]] = effect\n    time_records[[md]] = proc.time() - ptm\n    pbar$step()\n    }\n    results <- resamples(resample_list)\n    return(list(results,cal_results,time_records))\n}\n\ntemp = proc.time()\ntemp = proc.time() - temp",
    "created" : 1516687873694.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2317285617",
    "id" : "ACFB10DF",
    "lastKnownWriteTime" : 1517212835,
    "last_content_update" : 1517212835108,
    "path" : "~/R_Projects/ensemble_method/Rfile/Go_around_model_fun.R",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 13,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}