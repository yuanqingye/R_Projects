{
    "collab_server" : "",
    "contents" : "source('~/Rfile/R_impala.R')\nlastdate = Sys.Date()-1\nlast.date.str = format(lastdate,'%Y%m%d')\nspec.date.str = \"20171112\" #using 20171203 before\nspec.date.dash.str = \"2017-11-12\"\ncity_name = \"\"\n\n#dataset to be tested with umid,ip,city,model,stay time,pv count,# of umid per ip for z point and \n#time before spec date,for the same umid,model can't be diff but ip and city can  \nbase_sql = paste0(\"select base.*,umid_count_same_ip from \n                  (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n                  from dm.dm_app_pageview_info p where p.u_mid in (\",umid_sql,\") and dt <= '\",spec.date.str,\"' and path = 'z'\n                  group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info p where p.u_mid in \n                  (\",umid_sql,\") and dt <= '\",spec.date.str,\"' and path = 'z' group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n\n#get umid which introduce the order, which is unlikely, to be abnormal umid\norder_umid_sql = paste0(\"select distinct u_mid from ods.ods_tx_order_tx_order_dt o \ninner join ods.ods_app_pageview_info a on \n                        o.purchaser_id = a.u_id where substr(o.create_date,1,10)= '\",spec.date.dash.str,\"' \n                        and o.order_status not in (1,7,19) and o.order_type=1 and a.l_city like '\",city_name,\"%'\")\n\n#get umid which revisit our app during a long time\nlast_long_umid_sql = \"select distinct u_mid from \n(select u_mid,(max(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss'))-min(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss')))/(3600*24) time_inv from dm.dm_app_pageview_info group by u_mid) t where time_inv>60\"\n\n#This sql search for target umid, the sample rely on which we build the model\numid_sql = \"select u_mid from test.train_sample\"\n\numid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in \n('泉州','泉州市','quanzhou') and dt = '20171112' and path = 'z'\"\n\nqz_umid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in \n('泉州','泉州市','quanzhou') and dt = '20171112' and path = 'z'\"\n\nwz_umid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in \n('温州','温州市','wenzhou') and dt = '20171203' and path = 'z'\"\n\numid_sql = paste0(\"select distinct u_mid from (\",qz_umid_sql,\" union \",wz_umid_sql,\") df\")\nneg_umid_sql = paste0(\"select distinct u_mid from (\",order_umid_sql,\" union \",last_long_umid_sql,\") df\")\n\ncheck_sql = \"select u_mid,flag from test.train_sample\"\ncheck_umid_sql = \"select u_mid from test.train_sample\"\n\ntrain_sample_big = get_advbase_set(umid_sql,neg_umid_sql,complexity = TRUE)\n# check = read_data_impala_general(check_sql)\nmodel = run_flexible_sql(MODEL_SQL)\ncity = run_flexible_sql(CITY_SQL)\npage_city_dt = run_flexible_sql(PAGE_CITY_DT_FIRST_SQL)\npage_umid = run_flexible_sql(PAGE_UMID_FIRST_SQL)\npv_umid_unit_min = run_flexible_sql(PV_UMID_UNIT_MIN_SQL)\n\n#base umid with city attributes on a given day\nbase_city = merge(train_sample_big,city[city$dt == spec.date.str,],by.x = \"l_city\",by.y = \"l_city\",all.x = TRUE)\n#base umid with city and model attributes on a given day\nbase_city_model = merge(base_city,model[model$dt == spec.date.str,],by.x = \"d_model\",by.y = \"d_model\",all.x = TRUE)\nbase_city_model = data.table(base_city_model)\nbase_city_model_summary = base_city_model[,c(lapply(.SD[,sum_col,with=FALSE],sum),lapply(.SD[,avg_col,with=FALSE],mean),lapply(.SD[,min_col,with = FALSE],min),lapply(.SD[,max_col,with = FALSE],max)),by = \"u_mid\"]\nbase_city_model_summary = as.data.frame(base_city_model_summary)\nbase_city_model_move = merge(base_city_model_summary,umid_move,by.x = \"u_mid\",by.y = \"u_mid\",all.x = TRUE,all.y = FALSE)\n\nmove = get_base_with_restrict(umid_sql,mode = \"umidmove\")\nsample_train_base = merge(base_city_model_summary,move,by.x = \"u_mid\",by.y = \"u_mid\")\nsample_sign_SQL = \"select u_mid,flag as sign from test.train_sample\"\nsample_sign_df = read_data_impala_general(sample_sign_SQL)\nsample_train = merge(sample_train_base,sample_sign_df,by.x = \"u_mid\",by.y = \"u_mid\")\nsample_train = preprocess_train_data(sample_train)\nmodel_nb = naive_bayes(sign~.,sample_train[complete.cases(sample_train),])\n\ntrain_set = base_city_model_move[,pickedColums]\ntrain_base = train_set[complete.cases(train_set),]\ntrain_base = as.data.frame(train_base)\nx = train_base[,!(names(train_base) %in% \"sign\")]\ntrain_base$sign = as.factor(train_base$sign)\ny = train_base$sign\n\n#this can handle the miss value case\nlibrary(naivebayes)\nmodel_nb = naive_bayes(sign~.,train_set[complete.cases(train_set),])\nresult_nb = predict(model_nb,x)\nnb_list = calf1(y,result_nb)\nnb_f1 = nb_list$f1\nnb_AUC = calAUC(y,result_nb)\n\nlibrary(randomForest)\nmodel_random_forest = randomForest(sign~.,train_set[complete.cases(train_set),])\nresult_random_forest = predict(model_random_forest,train_set[complete.cases(train_set),!(names(train_set) %in% \"sign\")])\nrf_list = calf1(train_set[complete.cases(train_set),]$sign,result_random_forest)\nrf_AUC = calAUC(train_set[complete.cases(train_set),]$sign,result_random_forest)\n\nlibrary(e1071)\nmodel_svm = svm(sign~.,train_set)\nresult_svm = predict(model_svm,x)\nsvm_list = calf1(train_set[complete.cases(train_set),]$sign,result_svm)\nsvm_AUC = calAUC(train_set[complete.cases(train_set),]$sign,result_svm)\nsummary(model_svm)\n\n# library(EMCluster)\nlibrary(mclust)\nBIC <- mclustBIC(train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\"))])\nplot(BIC)\nsummary(BIC)\n\nICL = mclustICL(train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\"))])\nplot(ICL)\nsummary(ICL)\n\n# specificity(data = result,reference = ori_result)\n# sensitivity(data = result,reference = ori_result)\n#EEV\n#VII\n#The best for our company's data is VEV AUC:0.999093\ntrain_base = train_set[complete.cases(train_set),]\nset.seed(1000)\ntrain_index = sample(nrow(train_base),2/3*nrow(train_base))\ntrain_sample = train_base[train_index,]\ntest_sample = train_base[-train_index,]\n#VEV\n#\"VII\",\"VEV\"\n#VOLUME SHAPE ORIENTATION\nmEst = mstep(modelName = \"EEI\", data = train_set[,!(names(train_set)%in%c(\"sign\"))],z = unmap(train_set[,\"sign\"]))\nresult_em_user = em(modelName = mEst$modelName,data = test_set[,!(names(test_set)%in%c(\"sign\"))],\n                    parameters = mEst$parameters)\nem_result = ifelse(result_em_user$z[,1]-result_em_user$z[,2]>0,0,1)\nem_list = calf1(test_set[,\"sign\"],em_result)\nem_AUC = calAUC(test_set[,\"sign\"],em_result)\n\ntest = read_data_impala_general(check_sql)\ncolnames(test) = c(\"u_mid\",\"sign\")\ntest_base = get_advbase_set(check_umid_sql)\ntest_base_set = merge(test,test_base,by.x = \"u_mid\",by.y=\"u_mid\")\ntest_set = test_base_set[,pickedColums]\ntest_set = test_set[complete.cases(test_set),]\nx = test_set[,!(names(test_set) %in% \"sign\")]\ntest_set$sign = factor(test_set$sign,levels = c('0','1'))\ny = as.character(test_set$sign)\n\ntest_em_user = em(modelName = \"VII\",data = test_set[,!(names(test_set)%in%c(\"sign\"))],\n                  parameters = mEst$parameters)\nem_test_result = ifelse(test_em_user$z[,1]-test_em_user$z[,2]>0,0,1)\nem_test_list = calf1(y,em_test_result)\nem_test_AUC = calAUC(y,em_test_result)\n\nresult_nb = predict(model_nb,x)\nresult_nb = as.character(result_nb)\nnb_list = calf1(y,result_nb)\nnb_f1 = nb_list$f1\nnb_AUC = calAUC(y,result_nb)\n#draw a picture through cluster\nX = train_set[complete.cases(train_set),!(names(train_set)%in%c(\"sign\"))]\nBIC_2 <- mclustBIC(X,G=2) #We only need to consider the cases for 2 clusters\nplot(BIC_2)\nsummary(BIC_2)\nmod2 <- Mclust(X, x = BIC_2)\n# summary(mod2, parameters = TRUE)\nplot(mod2, what = \"classification\")\n#che\nclass = train_set[complete.cases(train_set),\"sign\"]\nclPairs(X, class)\n\n#VVV,EVV,VVE,VVI not correct\n\nmEst = mstep(modelName = \"VEV\", data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],z = unmap(train_set$sign))\nresult_em_user = em(modelName = mEst$modelName,data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],\n                    parameters = mEst$parameters)\nView(result_em_user$z)\n\nmEst = mstep(modelName = \"VEI\", data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],z = unmap(train_set$sign))\nresult_em_user = em(modelName = mEst$modelName,data = train_set[,!(names(train_set)%in%c(\"sign\",\"city_perc\"))],\n                    parameters = mEst$parameters)\nView(result_em_user$z)\n\n# base_sql_qingyuan = paste0(\"select base.*,umid_count_same_ip from \n# (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n#                            from dm.dm_app_pageview_info where l_city in ('清远','清远市','qingyuan','qingyuanshi') and dt = '\",spec.date.str,\"' and path = 'z'\n#                            group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info where l_city in \n#                            ('清远','清远市','qingyuan','qingyuanshi') \n#                            and dt = '\",spec.date.str,\"' and path = 'z' group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n\n#using one sign classification from SVM\nlibrary(e1071)\nmodel_svm_one_sample = svm(sign~.,one_sample_train_set,type = \"one-classification\")\nresult_svm_one_sample = predict(model_svm_one_sample,x)\n#test if this can work for multiclass\nmodel_svm2 = svm(sign~.,train_set,type = \"one-classification\")\nresult_svm2 = predict(model_svm2,train_set)\n",
    "created" : 1513836296453.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1890302416",
    "id" : "46BF7C94",
    "lastKnownWriteTime" : 1516095829,
    "last_content_update" : 1516095829580,
    "path" : "~/R_Projects/abnormal_activity_analysis/Rfile/Formal_Doc_Final.R",
    "project_path" : "Rfile/Formal_Doc_Final.R",
    "properties" : {
        "docOutlineVisible" : "0",
        "tempName" : "Untitled1"
    },
    "relative_order" : 1,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}