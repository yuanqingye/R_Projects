{
    "collab_server" : "",
    "contents" : "# source('~/Rfile/R_impala.R')\nlibrary(naivebayes)\nlibrary(mclust)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(readxl)\nlibrary(caret)\n\n#Calculate the f1, the important criteria for classification model\n#' Title\n#'\n#' @param real \n#' @param pred \n#'\n#' @return\n#' @export\n#'\n#' @examples\ncalf1 = function(real,pred){\n  accuracy = sum(real==pred)/length(real)\n  #precise定义为当你认为是真时，实际是真的比例\n  precise = sum(real==1&pred==1)/sum(pred==1)\n  #spec定义为实际是假时，你也认为是假的比例\n  spec = sum(real==0&pred==0)/sum(real==0)\n  #当实际是真时，你也认为是真的比例recall/sensitivity\n  recall=sens = sum(real==1&pred==1)/sum(real==1)\n  f1 = 2*precise*recall/(precise+recall)\n  return(list(f1=f1,accuracy = accuracy,specificity = spec,precise = precise,recall = recall))\n}\n\n#Calculate the f1, the important criteria for classification model\n#' Title\n#'\n#' @param real \n#' @param pred \n#' @param type \n#'\n#' @return\n#' @export\n#'\n#' @examples\ncalAR = function(real,pred,type=\"accuracy\"){\n  accuracy = sum(real==pred)/length(real)\n  #precise定义为当你认为是真时，实际是真的比例\n  precise = sum(real==1&pred==1)/sum(pred==1)\n  #spec定义为实际是假时，你也认为是假的比例\n  spec = sum(real==0&pred==0)/sum(real==0)\n  #当实际是真时，你也认为是真的比例recall/sensitivity\n  recall=sens = sum(real==1&pred==1)/sum(real==1)\n  #f1 the important judgement of the algorithm\n  f1 = 2*precise*recall/(precise+recall)\n  if(type == \"accuracy\"){\n    return(accuracy)\n  }\n  if(type == \"precise\"){\n    return(precise)\n  }\n  if(type == \"specification\"){\n    return(spec)\n    }\n  if(type == \"recall\"){\n    return(recall)\n  }\n  if(type == \"f1\"){\n    return(f1)\n  }\n  stop(\"You may not define a correct type for calculate\",call. = TRUE)\n}\n\n#Given the real and pred result, calculate the AUC\n#' Title\n#'\n#' @param real \n#' @param pred \n#'\n#' @return\n#' @export\n#'\n#' @examples\ncalAUC = function(real,pred){\n  library(AUC)\n  test_roc = roc(pred,real)\n  test_auc = auc(test_roc)\n  return(test_auc)\n}\n\n#' Title\n#'\n#' @param model \n#' @param newset \n#' @param keycol \n#' @param calf \n#' @param caltype \n#'\n#' @return\n#' @export\n#'\n#' @examples\ncal_model_accuracy = function(model,newset,keycol,calf,caltype)\n{\n  newset = newset[complete.cases(newset),]\n  model_result = predict(object = model,newdata = newset)\n  model_cal = calf(newset[,keycol],model_result,caltype)\n  return(model_cal)\n}\n\n#' Title\n#'\n#' @param v \n#' @param type \n#'\n#' @return\n#' @export\n#'\n#' @examples\nmakeSQLListFromVec = function(v,type = \"string\"){\n  result = \"(\"\n  k = 1\n  for(i in v){\n      if(type == \"string\"){\n        result = paste0(result,\"'\",i,\"'\")\n      }\n      else{\n        result = paste0(result,i)\n      }\n    if(k!=length(v)){\n      result = paste0(result,\",\")\n    }\n    k= k+1\n  }\n  result = paste0(result,\")\")\n  return(result)\n}\n\n#So the time is the ending time~ all the activity before that time is recorded\n#This function is for get the base umid related data set,with umid_sql to restrict the umid set\n#the extracted field is fixed\n#' Title\n#'\n#' @param umid_sql \n#' @param specDate \n#' @param mode \n#' @param mobile \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_base_with_restrict = function(umid_sql,specDate = spec.date.str,mode = \"base\",mobile = TRUE){\n  if(mode == \"base\"){\n    system = \" \"\n    if(mobile){\n      system = \" and platf_lv1='APP' \"\n    }\n    sql = paste0(\"select base.*,umid_count_same_ip,\",specDate,\" from \n                 (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n                 from dm.dm_app_pageview_info p where p.u_mid in (\",umid_sql,\") and dt <= '\",specDate,\"' and path = 'z' and cast(p_stay_time as int) < 1000*3600*6 and cast(p_stay_time as int) > 0\",system,\n                 \"group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info p where p.u_mid in \n                 (\",umid_sql,\") and dt <= '\",specDate,\"' and path = 'z'\",system,\"group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n  }\n  else if(mode == \"umidmove\"){\n    #a umid may shows up in more than one city\n    sql = paste0(\"select u_mid,count(distinct l_city) mobile_city_count,count(l_gps) mobile_gps_count,\",specDate,\" from dm.dm_app_pageview_info p \n                 where p.u_mid in (\",umid_sql,\") and dt <= '\",specDate,\"' and path = 'z'\",system,\"group by u_mid\")\n  }\n  base = read_data_impala_general(sql)\n  return(base)\n}\n\n#' Title\n#'\n#' @param umid_sql_list \n#' @param datelist \n#' @param mode \n#' @param mobile \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_base_with_restrict_union = function(umid_sql_list,datelist,mode = \"base\",mobile = TRUE){\n  sql = vector(mode = \"character\",length = 0)\n  system = \" \"\n  if(mobile){\n    system = \" and platf_lv1='APP' \"\n  }\n  for(i in 1:length(umid_sql_list)){\n    if(mode == \"base\"){\n        # sql[i] = paste0(\"select base.*,umid_count_same_ip,'\",datelist[i],\"' as dt from \n        #          (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv \n        #          from dm.dm_app_pageview_info p where p.u_mid in (\",umid_sql_list[i],\") and dt <= '\",datelist[i],\"' and path = 'z' and cast(p_stay_time as int) < 1000*3600*6 and cast(p_stay_time as int) > 0\",system,\n        #          \"group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info p where p.u_mid in \n        #          (\",umid_sql_list[i],\") and dt <= '\",datelist[i],\"' and path = 'z'\",system,\"group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n        sql[i] = paste0(\"select base.*,umid_count_same_ip from \n                 (select u_mid,l_ip,l_city,d_model,max(cast(p_stay_time as int)) max_stay,min(cast(p_stay_time as int)) min_stay,avg(cast(p_stay_time as int)) avg_stay,count(*) pv,max(cast(dt as int)) dt \n                        from dm.dm_app_pageview_info p where p.u_mid in (\",umid_sql_list[i],\") and dt <= '\",datelist[i],\"' and path = 'z' and cast(p_stay_time as int) < 1000*3600*6 and cast(p_stay_time as int) > 0\",system,\n                        \"group by u_mid,l_ip,l_city,d_model) base left join (select count(distinct u_mid) umid_count_same_ip,l_ip from dm.dm_app_pageview_info p where p.u_mid in \n                        (\",umid_sql_list[i],\") and dt <= '\",datelist[i],\"' and path = 'z'\",system,\"group by l_ip) iptb on base.l_ip = iptb.l_ip\")\n                         }\n    else if(mode == \"umidmove\"){\n    #a umid may shows up in more than one city\n        sql[i] = paste0(\"select u_mid,count(distinct l_city) mobile_city_count,count(l_gps) mobile_gps_count from dm.dm_app_pageview_info p \n                 where p.u_mid in (\",umid_sql_list[i],\") and dt <= '\",datelist[i],\"' and path = 'z'\",system,\"group by u_mid\")\n               }\n  }\n  if(length(umid_sql_list)>1){\n    sql = paste(sql,collapse =  \" union \")\n  # sql = paste0(\"select * from (\",sql,\")\")\n  }\n  base = read_data_impala_general(sql)\n  return(base)\n  }\n\n#With some CONSTANT SQL, We exchange the parameter to get large range of assisting data set\n#' Title\n#'\n#' @param SQL \n#' @param specDate \n#' @param specCity \n#'\n#' @return\n#' @export\n#'\n#' @examples\nrun_flexible_sql = function(SQL,specDate = last.date.str,specCity = city_name){\n  SQL = str_replace_all(SQL,'date_to_be_replaced',specDate)\n  SQL = str_replace_all(SQL,'city_to_be_replaced',specCity)\n  result = read_data_impala_general(SQL)\n  return(result)\n}\n\n#The function give the final test and train set\n#first using get_base_with_restrict,then replace by get_base_with_restrict_union 2018118\n#complexity indicate if we need to include the neg case,which is used to produce training\n#while the pure positive or negative case is used for test\n#' Title\n#'\n#' @param umid_sql \n#' @param neg_umid_sql \n#' @param specDate \n#' @param negspecDate \n#' @param renew \n#' @param complexity \n#' @param sign \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_advbase_set = function(umid_sql,neg_umid_sql,specDate,negspecDate = specDate,renew = FALSE,complexity = FALSE,sign = 1){\n  if(!complexity){\n    move = get_base_with_restrict_union(umid_sql,specDate,mode = \"umidmove\")\n    base = get_base_with_restrict_union(umid_sql,specDate)\n    move$sign = sign\n    }\n  else{\n    positive_base = get_base_with_restrict_union(umid_sql,specDate)\n    negative_base = get_base_with_restrict_union(neg_umid_sql,negspecDate)\n    #for positive and negative case, if duplicates occurs, we remove duplicates\n    positive_base = positive_base[!duplicated(positive_base[,c(\"u_mid\",\"l_city\",\"l_ip\",\"d_model\")]),]\n    negative_base = negative_base[!duplicated(negative_base[,c(\"u_mid\",\"l_city\",\"l_ip\",\"d_model\")]),]\n    base = rbind(positive_base,negative_base)\n    base = data.table(base)\n    base[,num:=.N,by = c(\"u_mid\",\"l_city\",\"l_ip\",\"d_model\")]\n    base = base[num<2,]\n    base = as.data.frame(base)\n    positive_move = get_base_with_restrict_union(umid_sql,specDate,mode = \"umidmove\")\n    negative_move = get_base_with_restrict_union(neg_umid_sql,negspecDate,mode = \"umidmove\")\n    positive_move$sign = 1\n    negative_move$sign = 0\n    move = rbind(positive_move,negative_move)\n    move = move[!duplicated(move$u_mid),]\n  }\n  #I didn't set the time because we always use\n  if(!exists(\"model\")|renew){\n    assign(\"model\",run_flexible_sql(MODEL_SQL),pos = .GlobalEnv)\n  }\n  if(!exists(\"city\")|renew){\n    assign(\"city\",run_flexible_sql(CITY_SQL),pos = .GlobalEnv)\n  }\n  if(!exists(\"page_city_dt\")|renew){\n    assign(\"page_city_dt\",run_flexible_sql(PAGE_CITY_DT_FIRST_SQL),pos = .GlobalEnv)\n  }\n  #base umid with city attributes on a given day\n  #unionDate = union(specDate,negspecDate)\n  #base_city = merge(base,city[city$dt %in% unionDate,],by.x = c(\"l_city\",\"dt\"),by.y = c(\"l_city\",\"dt\"),all.x = TRUE)\n  base_city = merge(base,city,by.x = c(\"l_city\",\"dt\"),by.y = c(\"l_city\",\"dt\"),all.x = TRUE)\n  #base umid with city and model attributes on a given day\n  base_city_model = merge(base_city,model,by.x = c(\"d_model\",\"dt\"),by.y = c(\"d_model\",\"dt\"),all.x = TRUE)\n  # base_city_model_pgperc = merge(base_city_model,page_city_dt[page_city_dt$dt %in% unionDate,],by.x = c(\"l_city\",\"dt\"),by.y = c(\"l_city\",\"dt\"),all.x = TRUE)\n  # base_city_model_pgperc = data.table(base_city_model_pgperc)\n  #duplicated umid should be take care of\n  base_city_model = data.table(base_city_model)\n  base_city_model_summary = base_city_model[,c(lapply(.SD[,sum_col,with=FALSE],sum,na.rm = TRUE),lapply(.SD[,avg_col,with=FALSE],mean,na.rm = TRUE),lapply(.SD[,min_col,with = FALSE],min,na.rm = TRUE),lapply(.SD[,max_col,with = FALSE],max,na.rm = TRUE)),by = \"u_mid\"]\n  base_city_model_summary = as.data.frame(base_city_model_summary)\n  base_city_model_move = merge(base_city_model_summary,move,by.x = \"u_mid\",by.y = \"u_mid\",all.x = TRUE,all.y = FALSE)\n  return(base_city_model_move)\n}\n\n#' Title\n#'\n#' @param city \n#' @param specDate \n#' @param func_umid_sql \n#' @param factordf \n#' @param renew \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_test_sample = function(city,specDate,func_umid_sql =1,factordf = 1,renew = FALSE){\n  if(func_umid_sql == 1){\n    func_umid_sql = paste0(\"select u_mid from dm.dm_app_pageview_info where l_city like '\",city,\"%' and dt = '\",specDate,\"' \")\n  }\n  base = get_advbase_set(func_umid_sql,specDate = specDate,renew = renew)\n  if(any(class(factordf) == 'data.frame')){\n    base = merge(base,factordf,by.x = \"u_mid\",by.y = \"u_mid\")\n  }\n  else{\n    base$sign = factor(factordf,levels = c('0','1'))\n  }\n  base_set = base[,pickedColums]\n  return(base_set)\n}\n\n#' Title\n#'\n#' @param city \n#' @param specDate \n#' @param func_umid_sql \n#' @param factordf \n#' @param test_model \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_test_sample_result = function(city,specDate,func_umid_sql =1,factordf = 1,test_model){\n  base_set = get_test_sample(city,specDate,func_umid_sql,factordf)\n  result_nb = predict(test_model,base_set[complete.cases(base_set),!(names(base_set) %in% \"sign\")])\n  result = cbind(base_set[complete.cases(base_set),!(names(base_set) %in% \"sign\")],result_nb)\n  nb_list = calf1(base_set[complete.cases(base_set),\"sign\"],result_nb)\n  return(list(nb_list,result))\n}\n\n#' Title\n#'\n#' @param name_para_sets \n#' @param factordf \n#' @param renew \n#'\n#' @return\n#' @export\n#'\n#' @examples\ncollect_test_set = function(name_para_sets,factordf = 1,renew = TRUE){\n  name_para_sets[[\"test_set_name\"]] = paste0(name_para_sets[[\"test_set_name\"]],str_sub(name_para_sets[[\"date\"]],5,8))\n  for(k in 1:nrow(name_para_sets)){\n    city = name_para_sets[[k,\"city\"]]\n    specDate = name_para_sets[[k,\"date\"]]\n    test_set_name = name_para_sets[[k,\"test_set_name\"]]\n    if(k > 1){\n      renew = FALSE\n    }\n    temp = get_test_sample(city = city,specDate = specDate,factordf = factordf,renew = renew)\n    assign(test_set_name,temp,envir = .GlobalEnv)\n      }\n}\n\n# go_around_test_result = function(test_set){\n#   for(k in 1:nrow(test_set)){\n#     city = test_set[k,\"city\"]\n#     specDate = test_set[k,\"date\"]\n#   }\n# }\n\n#' Title\n#'\n#' @param test_set_names \n#' @param model_names \n#'\n#' @return\n#' @export\n#'\n#' @examples\ntest_around_set = function(test_set_names, model_names) {\n  result_cal = data.frame()\n  for (test_set_name in test_set_names) {\n    for (model_name in model_names) {\n      test_model = get(model_name)\n      test_set = get(test_set_name)\n      result_cal[test_set_name,model_name] = cal_model_accuracy(\n        model = test_model,\n        newset = test_set,\n        keycol = \"sign\",\n        calf = calAR,\n        caltype = \"accuracy\"\n      )\n    }\n  }\n  return(result_cal)\n}\n\n#' Title\n#'\n#' @param original_set \n#'\n#' @return train_base\n#' @export\n#'\n#' @examples\npreprocess_train_data = function(original_set){\n  train_set = original_set[,pickedColums]\n  train_base = train_set[complete.cases(train_set),]\n  train_base = as.data.frame(train_base)\n  # x = train_base[,!(names(train_base) %in% \"sign\")]\n  train_base$sign = as.factor(train_base$sign)\n  # y = train_base$sign\n  return(train_base)\n}\n\n#' Title\n#'\n#' @param oringin_set \n#' @param keycol \n#' @param posdiv \n#' @param negdiv \n#' @param randnum \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_var_sample <- function(oringin_set,keycol = \"sign\",posdiv = 0.2,negdiv = 1,randnum = 999) {\n  set.seed(randnum)\n  posIndex = which(oringin_set[[keycol]] == 1)\n  negIndex = which(oringin_set[[keycol]] == 0)\n  samposIndex = sample(x = posIndex,size = length(posIndex)*posdiv,replace = FALSE)\n  samnegIndex = sample(x = negIndex,size = length(negIndex)*negdiv,replace = FALSE)\n  result_set = oringin_set[c(samnegIndex,samposIndex),]\n  return(result_set)\n}\n\n#' Title\n#'\n#' @param n \n#' @param train_set \n#'\n#' @return\n#' @export\n#'\n#' @examples\nmanually_repeat_nb_ml = function(n,train_set){\n  for(k in 1:n){\n    temp_model = naive_bayes(sign~.,train_set[complete.cases(train_set),])\n    assign(paste0(\"model\",k),temp_model,pos = .GlobalEnv)\n  }\n  result = test_around_set(test_set_names = test_set_names,model_names = paste0(\"model\",1:n))\n}\n\n#' Title\n#'\n#' @param dateset \n#' @param umid_sql \n#' @param renew \n#'\n#' @return\n#' @export\n#'\n#' @examples\nget_complex_train_set = function(dateset,umid_sql,renew = FALSE){\n  neg_umid_sql = c(order_umid_sql,last_long_umid_sql)\n  general_pn = get_advbase_set(umid_sql,neg_umid_sql,dateset,renew = renew,complexity = TRUE)\n  train_pn = preprocess_train_data(general_pn)\n  return(train_pn)\n}\n\n#' Title\n#'\n#' @param training_model \n#' @param specDate \n#' @param renew \n#'\n#' @return\n#' @export\n#'\n#' @examples\npred_day_result <- function(training_model,specDate = last.date.str,renew = TRUE) {\n  #get everyday's feature set\n  umid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where  dt = 'date_to_be_replaced' and path = 'z'\"\n  umid_sql = str_replace_all(umid_sql,'date_to_be_replaced',specDate)\n  general_today = get_advbase_set(umid_sql,specDate = specDate,renew = renew)\n  general_today = general_today[complete.cases(general_today),]\n  train_today = preprocess_train_data(general_today)\n  temp = predict(training_model,newdata = train_today,type = 'prob')\n  sign = ifelse(temp[[1]]>temp[[2]],0,1)\n  names(temp) = c(\"normal_prob\",\"abnorm_prob\")\n  today_result = data.frame(u_mid = general_today[,\"u_mid\"],sign,temp,dt = specDate)\n  return(today_result[complete.cases(today_result),])\n}",
    "created" : 1514967488237.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "2072321572",
    "id" : "DCBE01CD",
    "lastKnownWriteTime" : 1517911183,
    "last_content_update" : 1517911183013,
    "path" : "~/R_Projects/abnormal_activity_analysis/Rfile/test_func.R",
    "project_path" : "Rfile/test_func.R",
    "properties" : {
        "docOutlineSize" : "177.19217066483313",
        "docOutlineVisible" : "1",
        "tempName" : "Untitled1"
    },
    "relative_order" : 4,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}