{
    "collab_server" : "",
    "contents" : "#! /usr/bin/env Rscript\nsource('~/Rfile/R_impala.R')\nlibrary(stringr)\nlibrary(naivebayes)\nlibrary(mclust)\nlibrary(e1071)\nlibrary(randomForest)\nlibrary(readxl)\nlibrary(caret)\nlibrary(data.table)\nlibrary(abnormTestOnlineFunc)\n\n# pickedColums = c(\"max_stay\",\"min_stay\",\"avg_stay\",\"pv\",\"umid_count_same_ip\",\"sign\",\"city_perc\",\"md_perc\",\"mobile_city_count\",\"mobile_gps_count\",\"rate\")\npickedColums = c(\"max_stay\",\"min_stay\",\"avg_stay\",\"pv\",\"umid_count_same_ip\",\"sign\",\"city_perc\",\"md_perc\",\"mobile_city_count\",\"mobile_gps_count\")\nsum_col = c(\"pv\")\navg_col = c(\"city_perc\",\"md_perc\",\"avg_stay\")\nmax_col = c(\"max_stay\",\"umid_count_same_ip\")\nmin_col = c(\"min_stay\")\nlastdate = Sys.Date()-1\nlast.date.str = format(lastdate,'%Y%m%d')\nspec.date.str = \"20171112\" #using 20171203 before\nspec.date.dash.str = \"2017-11-12\"\ncity_name = \"\"\ntest_formula = as.formula(\"sign~.\")\ncontrol <- trainControl(method=\"repeatedcv\", number=10, repeats=3)\nmetric <- \"Accuracy\"\npreProcess=c(\"center\", \"scale\")\nsvmGrid = data.frame(sigma = 3.90625e-03, C = c(0.1,1,10,1000,10000))\n# train_pn = read_xlsx(\"~/data/test_abnormal_uv.xlsx\")\n\n#get umid which introduce the order, which is unlikely, to be abnormal umid\norder_umid_sql = paste0(\"select distinct u_mid from ods.ods_tx_order_tx_order_dt o \n                        inner join ods.ods_app_pageview_info a on \n                        o.purchaser_id = a.u_id where substr(o.create_date,1,10)= '\",spec.date.dash.str,\"' \n                        and o.order_status not in (1,7,19) and o.order_type=1 and a.l_city like '\",city_name,\"%'\")\n\n#get umid which revisit our app during a long time\nlast_long_umid_sql = \"select distinct u_mid from \n(select u_mid,(max(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss'))-min(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss')))/(3600*24) time_inv from dm.dm_app_pageview_info group by u_mid) t where time_inv>60\"\n\n#city and its umid count and new umid count and the rate of new count/all count,group by \n#city and the visit dt,only include umid before a specific date(BY LIMIT FIRSTONLINETIME TABLE)\n#duplicated umid is allowed, which means this is essentially \nCITY_SQL = \"select x.*,x.city_count_new/x.city_count_all city_perc from\n(select m.l_city,m.dt,count(*) city_count_all,count(if(m.isnew = 'new','new',NULL)) city_count_new from \n(select i.*,case when (regexp_replace(to_date(firstonlinetime),'-','')) = i.dt then 'new' else 'old' end isnew \nfrom dm.dm_app_pageview_info i inner join dl.umid_firstonlinetime f on i.u_mid = f.u_mid\nwhere f.dt = 'date_to_be_replaced') m group by m.l_city,m.dt) x\"\n\n#model and its umid count and new umid count and the rate of new count/all count group by \n#model and the visit dt,only include the umid before a specific date(BY LIMIT FIRSTONLINETIME TABLE)\nMODEL_SQL = \"select x.*,x.md_count_new/x.md_count_all md_perc from\n(select m.d_model,m.dt,count(*) md_count_all,count(if(m.isnew = 'new','new',NULL)) md_count_new from \n(select i.*,case when (regexp_replace(to_date(firstonlinetime),'-','')) = i.dt then 'new' else 'old' end isnew \nfrom dm.dm_app_pageview_info i inner join dl.umid_firstonlinetime f on i.u_mid = f.u_mid\nwhere f.dt = 'date_to_be_replaced') m group by m.d_model,m.dt) x\"\n\n#the percentage of each city's first ranking page count against the all count\nPAGE_CITY_FIRST_SQL= \"select * from\n(select t.l_city,t.p_count,ac.all_count,t.p_count/ac.all_count rate,row_number() over (partition by t.l_city order by p_count desc) rnum from\n(select l_city,count(*) p_count,p_type from dm.dm_app_pageview_info where dt <= 'date_to_be_replaced'  and path = 'z' group by l_city,p_type) t \nleft join (select l_city,count(*) all_count from dm.dm_app_pageview_info where dt <= 'date_to_be_replaced'  and path = 'z' group by l_city) ac \nusing(l_city)) tt where tt.rnum = 1\"\n\nPAGE_CITY_DT_FIRST_SQL= \"select * from\n(select t.l_city,t.dt,t.p_count,ac.all_count,t.p_count/ac.all_count rate,row_number() over (partition by t.l_city,t.dt order by p_count desc) rnum from\n(select l_city,dt,count(*) p_count,p_type from dm.dm_app_pageview_info where dt <= 'date_to_be_replaced'  and path = 'z' group by l_city,dt,p_type) t \nleft join (select l_city,dt,count(*) all_count from dm.dm_app_pageview_info where dt <= 'date_to_be_replaced'  and path = 'z' group by l_city,dt) ac \nusing(l_city,dt)) tt where tt.rnum = 1\"\n\n#the percentage of each umid's first ranking page count against the all count\nPAGE_UMID_FIRST_SQL = \"select * from\n(select t.u_mid,t.p_count,ac.all_count,t.p_count/ac.all_count rate,row_number() over (partition by t.u_mid order by p_count desc) rnum from\n(select u_mid,count(*) p_count,p_type from dm.dm_app_pageview_info where dt = 'date_to_be_replaced'  and path = 'z' group by u_mid,p_type) t \nleft join (select u_mid,count(*) all_count from dm.dm_app_pageview_info where dt = 'date_to_be_replaced'  and path = 'z' group by u_mid) ac \nusing(u_mid)) tt where tt.rnum = 1\"\n\n#get each umid's page view count per minute\nPV_UMID_UNIT_MIN_SQL = \"select u_mid,pcount,stay_time,pcount/stay_time pv from (\nselect u_mid,case when count(*)>1 then (max(cast(ts as bigint))-min(cast(ts as bigint)))/1000/60 \nelse cast(max(p_stay_time) as integer)/1000/60 end stay_time,\ncount(*) pcount from dm.dm_app_pageview_info where l_city like 'city_to_be_replaced%' and dt = 'date_to_be_replaced' \nand path = 'z' group by u_mid,session) t\"\norder_umid_sql = paste0(\"select distinct u_mid from ods.ods_tx_order_tx_order_dt o \ninner join ods.ods_app_pageview_info a on \n                        o.purchaser_id = a.u_id where substr(o.create_date,1,10)= '\",spec.date.dash.str,\"' \n                        and o.order_status not in (1,7,19) and o.order_type=1 and a.l_city like '\",city_name,\"%'\")\n\n#get umid which revisit our app during a long time\nlast_long_umid_sql = \"select distinct u_mid from \n(select u_mid,(max(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss'))-min(unix_timestamp(`system_time`, 'yyyy-MM-dd HH:mm:ss')))/(3600*24) time_inv from dm.dm_app_pageview_info group by u_mid) t where time_inv>60\"\n\nqz_umid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in \n('泉州','泉州市','quanzhou') and dt = '20171112' and path = 'z'\"\n\nwz_umid_sql = \"select distinct u_mid from dm.dm_app_pageview_info where l_city in \n('温州','温州市','wenzhou') and dt = '20171203' and path = 'z'\"\n\ndateset = c(\"20171112\",\"20171203\")\n#negdateset should be the same, due to the function setting we don't need to specify the same date\numid_sql = c(qz_umid_sql,wz_umid_sql)\nneg_umid_sql = c(order_umid_sql,last_long_umid_sql)\ngeneral_pn = get_advbase_set(umid_sql,neg_umid_sql,dateset,renew = TRUE,complexity = TRUE)\ntrain_pn = preprocess_train_data(general_pn)\n#model_nb_pn = naive_bayes(sign~.,train_pn[complete.cases(train_pn),])\nnaive_bayes_model = train(form = test_formula,data = train_pn,method = \"naive_bayes\",metric = metric,\n                          trControl = control,preProcess = preProcess)\n\n# general_today = get_advbase_set(umid_sql,specDate = last.date.str)\n# train_today = preprocess_train_data(general_today)\n# temp = predict(naive_bayes_model,newdata = train_today)\ntoday_result = pred_day_result(naive_bayes_model)\ntoday_result = today_result[complete.cases(today_result),]\n# today_result$u_mid = as.character(today_result$u_mid)\n# today_result$dt = as.character(today_result$dt)\ntoday_result$normal_prob = round(today_result$normal_prob,2)\ntoday_result$abnorm_prob = round(today_result$abnorm_prob,2)\ntoday_result[] = lapply(today_result,as.character)\n\nwrite.table(today_result,\"~/result/today_result.txt\",col.names = FALSE,row.names = FALSE,sep = \"\\t\")\ndbDisconnect(con)\n",
    "created" : 1517795457479.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "1226063318",
    "id" : "922B4A37",
    "lastKnownWriteTime" : 1520823192,
    "last_content_update" : 1520823192453,
    "path" : "~/R_Projects/abnormal_activity_analysis/Rfile/abnorm_test_online.R",
    "project_path" : "Rfile/abnorm_test_online.R",
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 2,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}