{
    "collab_server" : "",
    "contents" : "# source(\"~/Rfile/R_hive.R\")\nlibrary(openxlsx)\n# data_930 = read_data_hive_general(sql)\nsource('~/Rfile/R_impala.R')\n#1daily activity pvuv\npvuv_sql = \"select dt,\ncount(1) uv,\nsum(pv) pv ,\nsum(pv)/count(1) perpv,\ncount(if(isnew='new',1,null)) newuv ,\nsum(if(isnew='new',pv,0)) newpv, \nsum(if(isnew='new',pv,0))/count(if(isnew='new',1,null)) newperpv,\ncount(if(isnew='old',1,null)) olduv ,\nsum(if(isnew='old',pv,0)) oldpv, \nsum(if(isnew='old',pv,0))/count(if(isnew='old',1,null)) oldperpv\nfrom \ndl.umid_pv where dt>='20171008'\ngroup by dt\"\n\npvuv = read_data_impala_general(pvuv_sql)\npvuv = pvuv[order(pvuv$dt),]\n\n#考虑日活动量\npar(bg = 'black')\ncolors = rainbow(3)\nplot(pvuv$dt,pvuv$uv,col = colors[[1]],type = 'l',ylim = c(0,70000))\nlines(pvuv$dt,pvuv$newuv,col = colors[[2]],type = 'l')\nlines(pvuv$dt,pvuv$olduv,col = colors[[3]], type = 'l')\n\nlegend('topleft',c(\"uv\",\"newuv\",\"olduv\"),cex = 0.7,fill = colors,text.col= 'pink')\n\n#需要加入坐标轴\ntitle(main = '近两周日活',xlab = 'dates',ylab = '日活',col.main = 'blue',\n      col.lab = 'purple')\naxis(1,col = 'purple')\nat = axTicks(1)\nmtext(side = 1, text = at, at = at, col = \"purple\", line = 1)\n\naxis(2,col = 'purple')\nat = axTicks(2)\nmtext(side = 2,text = at,at = at,col = 'purple',line = 1)\n\nylarge = max(max(pvuv$perpv),max(pvuv$newperpv),max(pvuv$oldperpv))\n#考虑人均pv\nplot(pvuv$dt,pvuv$perpv,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))\nlines(pvuv$dt,pvuv$newperpv,col = colors[[2]],type = 'l')\nlines(pvuv$dt,pvuv$oldperpv,col = colors[[3]], type = 'l')\n\nlegend('topright',c(\"perpv\",\"newperpv\",\"oldperpv\"),cex = 0.7,fill = colors,text.col= 'pink')\n\n#需要加入坐标轴\ntitle(main = '近两周人均pv',xlab = 'dates',ylab = '人均pv',col.main = 'blue',\n      col.lab = 'purple')\naxis(1,col = 'purple')\nat = axTicks(1)\nmtext(side = 1, text = at, at = at, col = \"purple\", line = 1)\n\naxis(2,col = 'purple')\nat = axTicks(2)\nmtext(side = 2,text = at,at = at,col = 'purple',line = 1)\n\n\n#1daily activity depth\ndepth_sql = \"select a.dt,isnew,a.p_channel,b.depth,count(1) from \ndm.dm_app_umid_step a  \nleft outer join \ntest.pagelevel b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt>20171008 group by a.dt,isnew,b.depth,a.p_channel\n\"\ndepth = read_data_impala_general(depth_sql)\n\n#3conversion booking  \nbooking_sql = \"select regexp_replace(to_date(create_date),'-','') dt,\nc.openid,\n'booking' type\nfrom\nods.ods_jz_business_jz_activity_user_dt b \njoin \nods.ods_db_user_center_users_dt c on b.user_mobile=c.mobile\nwhere b.is_del=0 and to_date(create_date)>='2017-10-08'\ngroup by  \nregexp_replace(to_date(create_date),'-',''),c.openid\"\nbooking = read_data_impala_general(booking_sql)\n\n#3conversion order_online\norder_sql = \"select  \nregexp_replace(to_date(create_date),'-','') dt,\npurchaser_id openid,\n'orders' type from \nods.ods_tx_order_tx_order_dt a\nwhere \nto_date(create_date)>='2017-10-08' and \na.order_type=1  and plantform in (3) and a.order_status not  in (1,7,19) \ngroup by regexp_replace(to_date(create_date),'-',''),purchaser_id\"\norder_online = read_data_impala_general(order_sql)\n\n#3conversion coupon\ncoupon_sql = \"select  regexp_replace(to_date(create_time),'-','') dt,\nopen_id openid, 'coupon' type \nfrom ods.ods_marketing_center_mmc_user_coupon_dt where \nto_date(create_time)>='2017-10-08'\nand channel_id not in (2,4) and open_id!=''\ngroup by regexp_replace(to_date(create_time),'-',''),open_id;\"\ncoupon = read_data_impala_general(coupon_sql)\n\n#\n\nsource(\"~/Rfile/R_hive.R\")\n#1daily activity time span\ntime_span_sql = \"select dt,\n\tavg(persvg) totalavg,\n  avg(case when isnew ='new' then persvg else null end) newavg,\n  avg(case when isnew ='old' then persvg else null end) oldavg\n  from\n(\n  select a.dt,a.u_mid,\n  sum(CAST(p_stay_time AS INT))/1000/60 persvg,\n  case when regexp_replace(to_date(firstonlinetime),'-','')=a.dt then 'new' else 'old' end isnew \n  from \n  ods.ods_app_pageview_info a \n  left outer join \n  dl.umid_firstonlinetime b  on a.u_mid=b.u_mid \n  where a.dt>=20171008 and  b.dt=20171019 and\n  p_domain='mmall.com'    and service like '%staytime%' and substr(a.u_mid,1,2)!='a_' and path='z'  and l_city!='测试'\n  and p_type not in ('page.closedown','page.wakeup','page.activate.main') and length(p_stay_time)<=7\n  group by  a.dt,a.u_mid,case when regexp_replace(to_date(firstonlinetime),'-','')=a.dt then 'new' else 'old' end \n)a group by dt\"\n\ntime_span = read_data_hive_general(time_span_sql)\nwrite.xlsx(time_span,\"~/data/uc_analysis/time_span.xlsx\")\n#考虑time span,\nylarge = max(time_span[,2:4])\nplot(time_span$dt,time_span$totalavg,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))\nlines(time_span$dt,time_span$newavg,col = colors[[2]],type = 'l')\nlines(time_span$dt,time_span$oldavg,col = colors[[3]], type = 'l')\n\nlegend('topright',c(\"totalavg\",\"newavg\",\"oldavg\"),cex = 0.7,fill = colors,text.col= 'pink')\n\n#需要加入坐标轴\ntitle(main = '近两周用户活跃时长',xlab = 'dates',ylab = '',col.main = 'blue',\n      col.lab = 'purple')\naxis(1,col = 'purple')\nat = axTicks(1)\nmtext(side = 1, text = at, at = at, col = \"purple\", line = 1)\n\naxis(2,col = 'purple')\nat = axTicks(2)\nmtext(side = 2,text = at,at = at,col = 'purple',line = 1)\n\n#2persistency/stickness survival\nsurvival_sql = \"select \n\ta.dt,count(distinct a.u_mid) t,\n\t\t count(distinct case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),\n\t\t\t\t\t\tconcat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 then a.u_mid else null end)\tt1,\n\t\tcount(distinct if(a.isnew='new',a.u_mid,null)) newuv ,\n\t\t count(distinct case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),\n\t\t\t\t\t\tconcat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='new' then a.u_mid else null end)\tnewt1,\n\t\tcount(distinct if(a.isnew='old',a.u_mid,null)) olduv ,\n\t\t count(distinct case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),\n\t\t\t\t\t\tconcat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='old' then a.u_mid else null end)\tnoldt1\n\t\t\tfrom dl.umid_pv a\n\t\t\t\t\tleft outer join\n\t\t\t\t  dl.umid_pv b on a.u_mid=b.u_mid\t\t\n\t\t\t\t\twhere  a.dt>=20171008\tgroup by a.dt\"\n\nsurvival2 = read_data_hive_general(survival_sql)\nwrite.xlsx(survival,\"~/data/uc_analysis/survival.xlsx\")\n\n#考虑survival,!!须注意最后一天\nylarge = max(max(survival$t1/survival$t),max(survival$newt1/survival$newuv),max(survival$noldt1/survival$olduv))\nplot(survival$a.dt,survival$t1/survival$t,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))\nlines(survival$a.dt,survival$newt1/survival$newuv,col = colors[[2]],type = 'l')\nlines(survival$a.dt,survival$noldt1/survival$olduv,col = colors[[3]], type = 'l')\n\nlegend('topright',c(\"survival\",\"newsurvival\",\"oldsurvival\"),cex = 0.7,fill = colors,text.col= 'pink')\n\n#需要加入坐标轴\ntitle(main = '近两周次日留存率',xlab = 'dates',ylab = '留存率',col.main = 'blue',\n      col.lab = 'purple')\naxis(1,col = 'purple')\nat = axTicks(1)\nmtext(side = 1, text = at, at = at, col = \"purple\", line = 1)\n\naxis(2,col = 'purple')\nat = axTicks(2)\nmtext(side = 2,text = at,at = at,col = 'purple',line = 1)\n\n\n#3conversion im\nim_sql = \"select stat_date dt ,split(send,'_')[1] openid, 'im' type \nfrom \ndm.im_info a where split(send,'_')[0]=1 and stat_date>=20171008 and split(rec,'_')[0]=2\"\nim = read_data_hive_general(im_sql)\n\n#分维度分析新用户\nnew_user_sql = \"select f.u_mid,firstonlinetime,a.d_model,a.l_city from dl.umid_firstonlinetime f left join\n(select distinct u_mid,d_model,l_city from ods.ods_app_pageview_info where dt>= 20171008) a\non f.u_mid = a.u_mid where substr(firstonlinetime,1,10) >= '2017-10-08' \nand f.dt = '20171019'\"\nnew_user = read_data_hive_general(new_user_sql)\nunique_new_user = new_user[!duplicated(new_user$f.u_mid),]\nnew_user_table = data.table(unique_new_user)\nnew_user_table[,dt:=str_sub(firstonlinetime,1,10)]\n#不同手机型号新用户\nnew_user_by_model_date = new_user_table[a.d_model!=\"null\" & str_trim(a.d_model)!=\"\",.(numbers = .N),by = c(\"a.d_model\",\"dt\")]\nnew_user_by_model = new_user_table[a.d_model!=\"null\" & str_trim(a.d_model)!=\"\",.(numbers = .N),by = \"a.d_model\"][order(numbers,decreasing = T)]\nmodel_list = new_user_by_model[1:100,]$a.d_model\nnew_user_by_model_date_top100 = new_user_by_model_date[a.d_model %in% model_list,]\nnew_user_by_model_date_top100$model = factor(new_user_by_model_date_top100$a.d_model,levels = model_list)\nnew_user_by_model_date_top100_ordered = new_user_by_model_date_top100[order(dt,model)]\n\nnew_user_by_model_date_ordered_reshape = reshape(new_user_by_model_date_top100_ordered, idvar = \"model\", timevar = \"dt\", direction = \"wide\")\nnew_user_by_model_date_ordered_reshape = dcast(new_user_by_model_date_top100_ordered, model ~ dt, value.var = \"numbers\")\nnew_user_by_model_date_ordered_reshape$sum = rowSums(new_user_by_model_date_ordered_reshape[,-1],na.rm = T)\n\nwrite.xlsx(new_user_by_model_date_ordered_reshape,\"~/data/uc_analysis/model.xlsx\")\n\n#城市新用户\nnew_user_table$a.l_city = str_replace(new_user_table$a.l_city,\"市\",\"\")\nnew_user_by_city_dt = new_user_table[!a.l_city %in% c(\"null\",\"局域网\",\"未知\"),.(numbers = .N),by = c(\"a.l_city\",\"dt\")]\nnew_user_by_city = new_user_table[!a.l_city %in% c(\"null\",\"局域网\",\"未知\"),.(numbers = .N),by = \"a.l_city\"][order(numbers,decreasing = T),]\ncity_list = new_user_by_city[1:101,]$a.l_city\n\nnew_user_by_city_date_top100 = new_user_by_city_dt[a.l_city %in% city_list,]\nnew_user_by_city_date_top100$city = factor(new_user_by_city_date_top100$a.l_city,levels = city_list)\nnew_user_by_city_date_top100_ordered = new_user_by_city_date_top100[order(dt,city)]\n\nnew_user_by_city_date_ordered_reshape = dcast(new_user_by_city_date_top100_ordered, city ~ dt, value.var = \"numbers\")\nnew_user_by_city_date_ordered_reshape$sum = rowSums(new_user_by_city_date_ordered_reshape[,c(-1,-14)],na.rm = T)\n\nwrite.xlsx(new_user_by_city_date_ordered_reshape,\"~/data/uc_analysis/city.xlsx\")\n\n#渠道新用户\nchannel_sql = \"select * from dl.dl_channel_umid_openid where substr(umid_firstonlinetime,1,10) > '2017-10-07' and dt = 20171019\"\nnew_user_channel = read_data_impala_general(channel_sql)\ncolnames(new_user_channel) = str_replace(colnames(new_user_channel),\"dl_channel_umid_openid.\",\"\")\n# nrow(new_user_channel[!duplicated(new_user_channel$dl_channel_umid_openid.u_mid),])\n\nnew_user_channel_unique = new_user_channel[new_user_channel$dt==20171019,]\n# new_user_channel_unique = new_user_channel[!duplicated(new_user_channel$dl_channel_umid_openid.u_mid),]\nnew_user_channel_unique = data.table(new_user_channel_unique)\nnew_user_channel_unique$date = str_sub(new_user_channel_unique$umid_firstonlinetime,1,10)\nnew_user_by_channel_date = new_user_channel_unique[,.(numbers = .N),by = c(\"channel\",\"date\")]\nnew_user_by_channel = new_user_channel_unique[,.(numbers = .N),by = c(\"channel\")][order(numbers,decreasing = T)]\nchannel_list = new_user_by_channel$channel\nnew_user_by_channel_date_top = new_user_by_channel_date\nnew_user_by_channel_date_top$channels = factor(new_user_by_channel_date_top$channel,levels = channel_list)\nnew_user_by_channel_date_top_ordered = new_user_by_channel_date_top[order(date,channels)]\nnew_user_by_channel_date_ordered_reshape = dcast(new_user_by_channel_date_top_ordered, channels ~ date, value.var = \"numbers\")\nnew_user_by_channel_date_ordered_reshape$sum = rowSums(new_user_by_channel_date_ordered_reshape[,c(-1)],na.rm = T)\n\nwrite.xlsx(new_user_by_channel_date_ordered_reshape,\"~/data/uc_analysis/channel.xlsx\")\ncolors = rainbow(ncol(new_user_by_channel_date_ordered_reshape))\nmatrix = as.matrix(new_user_by_channel_date_ordered_reshape[1:10,-1])\nregions = new_user_by_channel_date_ordered_reshape$channels[1:10]\nL = ncol(matrix)\nbarplot(matrix[1:10,-L],main=\"channel\",names.arg=colnames(new_user_by_channel_date_ordered_reshape[,c(-1,-(L+1))]),xlab=\"date\",ylab=\"number\",col=colors)\nlegend(\"center\", legend = regions, cex=0.6, fill=colors)\n\n\n# dcast(dat1, name ~ numbers, value.var = \"value\")\n# xtabs(N ~ model + dt, data = new_user_by_model_date_top100_ordered)\n# reshape(dat1, idvar = \"name\", timevar = \"numbers\", direction = \"wide\")\n\n\n",
    "created" : 1508207808738.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "768233581",
    "id" : "A131DED7",
    "lastKnownWriteTime" : 1508923861,
    "last_content_update" : 1508923861288,
    "path" : "~/Rfile/uc_analysis_1017.R",
    "project_path" : null,
    "properties" : {
        "tempName" : "Untitled1"
    },
    "relative_order" : 9,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}