datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
survival_sql = paste0("select
a.dt,ndv(a.u_mid) t,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 then a.u_mid else null end)	t1,
ndv(if(a.isnew='new',a.u_mid,null)) newuv ,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 and a.isnew='new' then a.u_mid else null end) newt1,
ndv(if(a.isnew='old',a.u_mid,null)) olduv,
ndv(case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='old' then a.u_mid else null end) noldt1
from dl.umid_pv a
left outer join
dl.umid_pv b on a.u_mid=b.u_mid
where  a.dt>='",datestart.str,"' group by a.dt")
survival = read_data_impala_general(survival_sql)
# survival = read_data_hive_general(survival_sql)
survival = survival[order(survival$dt),]
survival = survival[-nrow(survival),]
survival$fdt = as.factor(survival$dt)
par(bg = 'black')
colors = rainbow(3)
#考虑survival,!!须注意最后一天
ylarge = max(max(survival$t1/survival$t),max(survival$newt1/survival$newuv),max(survival$noldt1/survival$olduv))
plot(as.numeric(survival$fdt),survival$t1/survival$t,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))
lines(as.numeric(survival$fdt),survival$newt1/survival$newuv,col = colors[[2]],type = 'l')
lines(as.numeric(survival$fdt),survival$noldt1/survival$olduv,col = colors[[3]], type = 'l')
legend('topright',c("survival","newsurvival","oldsurvival"),cex = 0.7,fill = colors,text.col= 'pink')
#需要加入坐标轴
title(main = '近两周次日留存率',xlab = 'dates',ylab = '留存率',col.main = 'blue',
col.lab = 'purple')
axis(1,col = 'purple')
at = str_sub(survival$dt,5,8)[seq(from = 2,to = 14,by = 2)]
mtext(side = 1, text = at, at = seq(from = 2,to = 14,by = 2), col = "purple", line = 1)
axis(2,col = 'purple')
at = axTicks(2)
mtext(side = 2,text = at,at = at,col = 'purple',line = 1)
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
survival_sql = paste0("select
a.dt,ndv(a.u_mid) t,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 then a.u_mid else null end)	t1,
ndv(if(a.isnew='new',a.u_mid,null)) newuv ,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 and a.isnew='new' then a.u_mid else null end) newt1,
ndv(if(a.isnew='old',a.u_mid,null)) olduv,
ndv(case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='old' then a.u_mid else null end) noldt1
from dl.umid_pv a
left outer join
dl.umid_pv b on a.u_mid=b.u_mid
where  a.dt>='",datestart.str,"' group by a.dt")
survival = read_data_impala_general(survival_sql)
# survival = read_data_hive_general(survival_sql)
survival = survival[order(survival$dt),]
survival = survival[-nrow(survival),]
survival$fdt = as.factor(survival$dt)
par(bg = 'black')
colors = rainbow(3)
#考虑survival,!!须注意最后一天
ylarge = max(max(survival$t1/survival$t),max(survival$newt1/survival$newuv),max(survival$noldt1/survival$olduv))
plot(as.numeric(survival$fdt),survival$t1/survival$t,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))
lines(as.numeric(survival$fdt),survival$newt1/survival$newuv,col = colors[[2]],type = 'l')
lines(as.numeric(survival$fdt),survival$noldt1/survival$olduv,col = colors[[3]], type = 'l')
legend('topright',c("survival","newsurvival","oldsurvival"),cex = 0.7,fill = colors,text.col= 'pink')
#需要加入坐标轴
title(main = '近两周次日留存率',xlab = 'dates',ylab = '留存率',col.main = 'blue',
col.lab = 'purple')
axis(1,col = 'purple')
at = str_sub(survival$dt,5,8)[seq(from = 2,to = 14,by = 2)]
mtext(side = 1, text = at, at = seq(from = 2,to = 14,by = 2), col = "purple", line = 1)
axis(2,col = 'purple')
at = axTicks(2)
mtext(side = 2,text = at,at = at,col = 'purple',line = 1)
##results = hide
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.75,
y = 0.25, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
survival_sql = paste0("select
a.dt,ndv(a.u_mid) t,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 then a.u_mid else null end)	t1,
ndv(if(a.isnew='new',a.u_mid,null)) newuv ,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 and a.isnew='new' then a.u_mid else null end) newt1,
ndv(if(a.isnew='old',a.u_mid,null)) olduv,
ndv(case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='old' then a.u_mid else null end) noldt1
from dl.umid_pv a
left outer join
dl.umid_pv b on a.u_mid=b.u_mid
where  a.dt>='",datestart.str,"' group by a.dt")
survival = read_data_impala_general(survival_sql)
# survival = read_data_hive_general(survival_sql)
survival = survival[order(survival$dt),]
survival = survival[-nrow(survival),]
survival$fdt = as.factor(survival$dt)
par(bg = 'black')
colors = rainbow(3)
#考虑survival,!!须注意最后一天
ylarge = max(max(survival$t1/survival$t),max(survival$newt1/survival$newuv),max(survival$noldt1/survival$olduv))
plot(as.numeric(survival$fdt),survival$t1/survival$t,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))
lines(as.numeric(survival$fdt),survival$newt1/survival$newuv,col = colors[[2]],type = 'l')
lines(as.numeric(survival$fdt),survival$noldt1/survival$olduv,col = colors[[3]], type = 'l')
legend('topright',c("survival","newsurvival","oldsurvival"),cex = 0.7,fill = colors,text.col= 'pink')
#需要加入坐标轴
title(main = '近两周次日留存率',xlab = 'dates',ylab = '留存率',col.main = 'blue',
col.lab = 'purple')
axis(1,col = 'purple')
at = str_sub(survival$dt,5,8)[seq(from = 2,to = 14,by = 2)]
mtext(side = 1, text = at, at = seq(from = 2,to = 14,by = 2), col = "purple", line = 1)
axis(2,col = 'purple')
at = axTicks(2)
mtext(side = 2,text = at,at = at,col = 'purple',line = 1)
#1daily activity pvuv
pvuv_sql = paste0("select dt,
count(1) uv,
sum(pv) pv ,
sum(pv)/count(1) perpv,
count(if(isnew='new',1,null)) newuv ,
sum(if(isnew='new',pv,0)) newpv,
sum(if(isnew='new',pv,0))/count(if(isnew='new',1,null)) newperpv,
count(if(isnew='old',1,null)) olduv ,
sum(if(isnew='old',pv,0)) oldpv,
sum(if(isnew='old',pv,0))/count(if(isnew='old',1,null)) oldperpv
from
dl.umid_pv where dt>='",ldatestart.str,
"'group by dt")
mpvuv = read_data_impala_general(pvuv_sql)
mpvuv = mpvuv[order(mpvuv$dt),]
xlarge = nrow(mpvuv)
xmid = floor(xlarge/2+0.5)+1
pvuv = mpvuv[xmid:xlarge,]
wpvuv = pvuv
pvuv$fdt = as.factor(pvuv$dt)
matrix = as.matrix(cbind(newuv = pvuv$newuv,olduv = pvuv$olduv))
matrix = t(matrix)
maxy = max(pvuv$uv)
maxx = pvuv[which.max(pvuv$uv),"dt"]
meany = mean(pvuv$uv)
newbetterthanold = sum(pvuv$newuv>pvuv$olduv)
abnormalhighdt = pvuv[pvuv$uv>1.3*meany,"dt"]
abnormallowdt = pvuv[pvuv$uv<0.7*meany,"dt"]
par(bg = 'white')
colors <- c("green","red")
dates <- pvuv$dt
stacks <- c("Old","New")
bplot = barplot(matrix,main="Every day uv",names.arg=dates,xlab="month",ylab="uv",col=colors,legend.text = stacks,args.legend = list(x = 0,y = maxy, stacks, cex=0.7, fill=colors,xjust = 0, yjust = 1))
par(bg = 'black')
colors = rainbow(3)
ylarge = max(max(pvuv$perpv),max(pvuv$newperpv),max(pvuv$oldperpv))
tmax = max(pvuv$perpv)
dttmax = pvuv[which.max(pvuv$perpv),"dt"]
tmin = min(pvuv$perpv)
dttmin = pvuv[which.min(pvuv$perpv),"dt"]
tmean = mean(pvuv$perpv)
nmax = max(pvuv$newperpv)
dtnmax = pvuv[which.max(pvuv$newperpv),"dt"]
nmin = min(pvuv$newperpv)
dtnmin = pvuv[which.min(pvuv$newperpv),"dt"]
nmean = mean(pvuv$newperpv)
omax = max(pvuv$oldperpv)
dtomax = pvuv[which.max(pvuv$oldperpv),"dt"]
omin = min(pvuv$oldperpv)
dtomin = pvuv[which.min(pvuv$oldperpv),"dt"]
omean = mean(pvuv$oldperpv)
newbetterthanold = sum(pvuv$newperpv>pvuv$oldperpv)
difftrend = pvuv[!(c(1,sign(diff(pvuv$newperpv)*diff(pvuv$oldperpv)))+1),"dt"]
#考虑人均pv
plot(as.numeric(pvuv$fdt),pvuv$perpv,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))
lines(as.numeric(pvuv$fdt),pvuv$newperpv,col = colors[[2]],type = 'l')
lines(as.numeric(pvuv$fdt),pvuv$oldperpv,col = colors[[3]], type = 'l')
legend('bottomright',c("perpv","newperpv","oldperpv"),cex = 0.7,fill = colors,text.col= 'pink')
#需要加入坐标轴
title(main = '近两周人均pv',xlab = 'dates',ylab = '人均pv',col.main = 'blue',
col.lab = 'purple')
axis(1,col = 'purple')
at = str_sub(pvuv$dt,5,8)[seq(from = 2,to = 14,by = 2)]
mtext(side = 1, text = at, at = seq(from = 2,to = 14,by = 2), col = "purple", line = 1)
axis(2,col = 'purple')
at = axTicks(2)
mtext(side = 2,text = at,at = at,col = 'purple',line = 1)
##results = hide
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.75,
y = 0.25, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "")
time_span_sql = paste0("select dt,
avg(persvg) totalavg,
avg(case when isnew ='new' then persvg else null end) newavg,
avg(case when isnew ='old' then persvg else null end) oldavg
from
(
select a.dt,a.u_mid,
sum(CAST(p_stay_time AS INT))/1000/60 persvg,
case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end isnew
from
ods.ods_app_pageview_info a
left outer join
dl.umid_firstonlinetime b on a.u_mid=b.u_mid
where a.dt>=",datestart.str," and b.dt='",dateend.str,"' and
p_domain='mmall.com' and service like '%staytime%' and substr(a.u_mid,1,2)!='a_' and path='z'  and l_city!='测试'
and p_type not in ('page.closedown','page.wakeup','page.activate.main') and length(p_stay_time)<=7
group by a.dt,a.u_mid,case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end
)a group by dt")
time_span = read_data_impala_general(time_span_sql)
time_span = time_span[order(time_span$dt),]
# write.xlsx(time_span,"~/data/uc_analysis/time_span.xlsx")
time_span$fdt = as.factor(time_span$dt)
time_span.new = time_span[,-1]
timespan.m <- melt(time_span.new)
timespan.m <- ddply(timespan.m, .(variable), transform,rescale = rescale(value))
timespan.m$dates = str_sub(as.character(timespan.m$fdt),6,8)
timespan.m$dates = factor(timespan.m$dates, levels = timespan.m$dates)
names(timespan.m) = c("fdt","old_new_user","time_span","rescale","dates")
# (p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple"))
p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple")
df = as.data.frame(t(time_span.new))
colnames(df) = time_span.new$fdt
df = df[-nrow(df),]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tbl1 <- tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tbl2 <- tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
# Plot chart and table into one object
grid.arrange(p, tbl1,tbl2,nrow=3,as.table=TRUE
# ,heights=c(3,1)
)
# plot_grid(p, tbl1, tbl2, align = "v", nrow = 3, rel_heights = c(1/2, 1/4, 1/4))
# rownames(time_span.new) = time_span.new$fdt
# DT::datatable(time_span.new[,-ncol(time_span.new)])
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)),padding = 8)
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)),padding = unit(c(4, 4), "mm"))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
grid.arrange(tb1,tb2,nrow = 2)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)),padding = unit(c(2, 2), "mm"))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
grid.arrange(tb1,tb2,nrow = 2)
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
grid.arrange(p,tb1,tb2,nrow = 3)
pl <- lapply(1:11, function(.x) qplot(1:10, rnorm(10), main=paste("plot", .x)))
ml <- marrangeGrob(pl, nrow=2, ncol=2)
ml
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = arrangeGrob(tb1,tb2,nrow = 2)
grid.arrange(p,tb_1_2,nrow = 2)
tb_1_2
p
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = marrangeGrob(tb1,tb2,nrow = 2)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = marrangeGrob(tb1,tb2,nrow = 2,ncol = 1)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = marrangeGrob(list(tb1,tb2),nrow = 2,ncol = 1)
grid.arrange(p,tb_1_2,nrow = 2)
tb_1_2
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = arrangeGrob(grobs = list(tb1,tb2),nrow = 2,ncol = 1)
grid.arrange(p,tb_1_2,nrow = 2)
tb_1_2
grid.arrange(tb_1_2)
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p = p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
tb_1_2 = arrangeGrob(grobs = list(tb1,tb2),nrow = 2,ncol = 1)
grid.arrange(p,tb_1_2,nrow = 2,ncol = 1)
