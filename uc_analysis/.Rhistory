# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.6,
y = 0.4, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.7,
y = 0.45, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.73,
y = 0.48, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.75,
y = 0.49, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.75,
y = 0.49, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
Sys.setlocale(category = "LC_ALL", locale = "")
time_span_sql = paste0("select dt,
avg(persvg) totalavg,
avg(case when isnew ='new' then persvg else null end) newavg,
avg(case when isnew ='old' then persvg else null end) oldavg
from
(
select a.dt,a.u_mid,
sum(CAST(p_stay_time AS INT))/1000/60 persvg,
case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end isnew
from
ods.ods_app_pageview_info a
left outer join
dl.umid_firstonlinetime b on a.u_mid=b.u_mid
where a.dt>=",datestart.str," and b.dt='",dateend.str,"' and
p_domain='mmall.com' and service like '%staytime%' and substr(a.u_mid,1,2)!='a_' and path='z'  and l_city!='测试'
and p_type not in ('page.closedown','page.wakeup','page.activate.main') and length(p_stay_time)<=7
group by a.dt,a.u_mid,case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end
)a group by dt")
time_span = read_data_impala_general(time_span_sql)
time_span = time_span[order(time_span$dt),]
# write.xlsx(time_span,"~/data/uc_analysis/time_span.xlsx")
time_span$fdt = as.factor(time_span$dt)
time_span.new = time_span[,-1]
timespan.m <- melt(time_span.new)
timespan.m <- ddply(timespan.m, .(variable), transform,rescale = rescale(value))
timespan.m$dates = str_sub(as.character(timespan.m$fdt),5,8)
timespan.m$dates = factor(timespan.m$dates, levels = timespan.m$dates)
names(timespan.m) = c("fdt","old_new_user","time_span","rescale","dates")
# (p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple"))
p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple")
df = as.data.frame(t(time_span.new))
colnames(df) = time_span.new$fdt
df = df[-nrow(df),]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tbl1 <- tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tbl2 <- tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
# Plot chart and table into one object
grid.arrange(p, tbl1,tbl2,nrow=3,as.table=TRUE
# ,heights=c(3,1)
)
# plot_grid(p, tbl1, tbl2, align = "v", nrow = 3, rel_heights = c(1/2, 1/4, 1/4))
# rownames(time_span.new) = time_span.new$fdt
# DT::datatable(time_span.new[,-ncol(time_span.new)])
Sys.setlocale(category = "LC_ALL", locale = "")
time_span_sql = paste0("select dt,
avg(persvg) totalavg,
avg(case when isnew ='new' then persvg else null end) newavg,
avg(case when isnew ='old' then persvg else null end) oldavg
from
(
select a.dt,a.u_mid,
sum(CAST(p_stay_time AS INT))/1000/60 persvg,
case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end isnew
from
ods.ods_app_pageview_info a
left outer join
dl.umid_firstonlinetime b on a.u_mid=b.u_mid
where a.dt>=",datestart.str," and b.dt='",dateend.str,"' and
p_domain='mmall.com' and service like '%staytime%' and substr(a.u_mid,1,2)!='a_' and path='z'  and l_city!='测试'
and p_type not in ('page.closedown','page.wakeup','page.activate.main') and length(p_stay_time)<=7
group by a.dt,a.u_mid,case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end
)a group by dt")
time_span = read_data_impala_general(time_span_sql)
time_span = time_span[order(time_span$dt),]
# write.xlsx(time_span,"~/data/uc_analysis/time_span.xlsx")
time_span$fdt = as.factor(time_span$dt)
time_span.new = time_span[,-1]
timespan.m <- melt(time_span.new)
timespan.m <- ddply(timespan.m, .(variable), transform,rescale = rescale(value))
timespan.m$dates = str_sub(as.character(timespan.m$fdt),5,8)
timespan.m$dates = factor(timespan.m$dates, levels = timespan.m$dates)
names(timespan.m) = c("fdt","old_new_user","time_span","rescale","dates")
# (p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple"))
p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple")
df = as.data.frame(t(time_span.new))
colnames(df) = time_span.new$fdt
df = df[-nrow(df),]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tbl1 <- tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tbl2 <- tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
# Plot chart and table into one object
grid.arrange(p, tbl1,tbl2,nrow=3,as.table=TRUE
# ,heights=c(3,1)
)
# plot_grid(p, tbl1, tbl2, align = "v", nrow = 3, rel_heights = c(1/2, 1/4, 1/4))
# rownames(time_span.new) = time_span.new$fdt
# DT::datatable(time_span.new[,-ncol(time_span.new)])
# datestart = as.Date("2017-12-02","%Y-%m-%d")
# dateend = datestart+14
# datestart.str = format(datestart,'%Y%m%d')
# dateend.str = format(dateend,'%Y%m%d')
# ldateend = datestart-1
# ldatestart = datestart-15
# ldatestart.str = format(ldatestart,'%Y%m%d')
# ldateend.str = format(ldateend,'%Y%m%d')
new_user_by_model_date_city_sql =
paste0("select count(b.u_mid) numbers,firstdt,d_model,l_city from
(select f.u_mid,substr(firstonlinetime,1,10) firstdt,a.d_model,a.l_city from dl.umid_firstonlinetime f left join
(select * from
(select u_mid,d_model,l_city,ROW_NUMBER() OVER (PARTITION BY u_mid,d_model,l_city ORDER BY dt)
as level from ods.ods_app_pageview_info where dt>=",ldatestart.str,") t where t.level = 1) a
using(u_mid) where substr(firstonlinetime,1,10) >= '",as.character(ldatestart),"'
and f.dt = '",dateend.str,"') b group by firstdt,d_model,l_city")
new_user_by_model_date_city = read_data_impala_general(new_user_by_model_date_city_sql)
new_user_by_model_date_city = data.table(new_user_by_model_date_city)
lnew_user_by_model_date_city = new_user_by_model_date_city[firstdt < as.character(datestart),]
new_user_by_model_date_city = new_user_by_model_date_city[firstdt >= as.character(datestart),]
new_user_by_model_date = new_user_by_model_date_city[d_model!="null" & str_trim(d_model)!="",.(numbers = sum(numbers)),by = c("d_model","firstdt")]
new_user_by_model = new_user_by_model_date_city[d_model!="null" & str_trim(d_model)!="",.(numbers = sum(numbers)),by = "d_model"][order(numbers,decreasing = T)]
model_list = new_user_by_model[1:100,]$d_model
new_user_by_model_date_top100 = new_user_by_model_date[d_model %in% model_list,]
new_user_by_model_date_top100$model = factor(new_user_by_model_date_top100$d_model,levels = model_list)
new_user_by_model_date_top100_ordered = new_user_by_model_date_top100[order(firstdt,model)]
# new_user_by_model_date_ordered_reshape = reshape(new_user_by_model_date_top100_ordered, idvar = "model", timevar = "firstdt", direction = "wide")
new_user_by_model_date_ordered_reshape = dcast(new_user_by_model_date_top100_ordered, model ~ firstdt, value.var = "numbers")
new_user_by_model_date_ordered_reshape$sum =rowSums(new_user_by_model_date_ordered_reshape[,-1],na.rm = T)
melt_df_model_top20 = melt(new_user_by_model_date_ordered_reshape[1:20,-ncol(new_user_by_model_date_ordered_reshape)], id.vars = "model", measure.vars = 2:(ncol(new_user_by_model_date_ordered_reshape)-1), variable.name = "date", value.name = "value")
lmodel_rank = lnew_user_by_model_date_city[d_model!="null" & str_trim(d_model)!="",.(lsum = sum(numbers)),by = c("d_model")]
lmodel_rank$lrank = frank(lmodel_rank,-lsum,ties.method = "min")
new_user_by_model_date_ordered_reshape$rank = seq(new_user_by_model_date_ordered_reshape$sum)
new_user_by_model_date_ordered_reshape = merge(new_user_by_model_date_ordered_reshape,lmodel_rank,by.x = "model",by.y= "d_model",all.x = TRUE)
new_user_by_model_date_ordered_reshape = new_user_by_model_date_ordered_reshape[order(new_user_by_model_date_ordered_reshape$rank),]
rankchange = new_user_by_model_date_ordered_reshape$lrank - new_user_by_model_date_ordered_reshape$rank
symrankchange = ifelse(is.na(rankchange)|rankchange==0,"",ifelse(rankchange>0,intToUtf8(9650),intToUtf8(9660)))
sym = paste0(rankchange,symrankchange)
new_user_by_model_date_ordered_reshape$lsum = NULL
new_user_by_model_date_ordered_reshape$lrank = NULL
new_user_by_model_date_ordered_reshape = cbind(sym,new_user_by_model_date_ordered_reshape)
rownames(new_user_by_model_date_ordered_reshape) = 1:nrow(new_user_by_model_date_ordered_reshape)
DT::datatable(new_user_by_model_date_ordered_reshape, options = list(pageLength = 20))
new_user_by_model_date_city$l_city = str_replace(new_user_by_model_date_city$l_city,"市","")
new_user_by_city_dt = new_user_by_model_date_city[!l_city %in% c("null","局域网","未知"),.(numbers = sum(numbers)),by = c("l_city","firstdt")]
new_user_by_city = new_user_by_model_date_city[!l_city %in% c("null","局域网","未知"),.(numbers = sum(numbers)),by = "l_city"][order(numbers,decreasing = T),]
city_list = new_user_by_city[1:101,]$l_city
new_user_by_city_date_top100 = new_user_by_city_dt[l_city %in% city_list,]
new_user_by_city_date_top100$city = factor(new_user_by_city_date_top100$l_city,levels = city_list)
new_user_by_city_date_top100_ordered = new_user_by_city_date_top100[order(firstdt,city)]
new_user_by_city_date_ordered_reshape = dcast(new_user_by_city_date_top100_ordered, city ~ firstdt, value.var = "numbers")
new_user_by_city_date_ordered_reshape$sum = rowSums(new_user_by_city_date_ordered_reshape[,c(-1,-14)],na.rm = T)
melt_df_city_top20 = melt(new_user_by_city_date_ordered_reshape[1:20,-ncol(new_user_by_city_date_ordered_reshape)], id.vars = "city", measure.vars = 2:(ncol(new_user_by_city_date_ordered_reshape)-1), variable.name = "date", value.name = "value")
lnew_user_by_model_date_city$l_city = str_replace(lnew_user_by_model_date_city$l_city,"市","")
lcity_rank = lnew_user_by_model_date_city[!l_city %in% c("null","局域网","未知"),.(lsum = sum(numbers)),by = c("l_city")]
lcity_rank$lrank = frank(lcity_rank,-lsum,ties.method = "min")
new_user_by_city_date_ordered_reshape$rank = seq(new_user_by_city_date_ordered_reshape$sum)
new_user_by_city_date_ordered_reshape = merge(new_user_by_city_date_ordered_reshape,lcity_rank,by.x = "city",by.y= "l_city",all.x = TRUE)
new_user_by_city_date_ordered_reshape = new_user_by_city_date_ordered_reshape[order(new_user_by_city_date_ordered_reshape$rank),]
rankchange = new_user_by_city_date_ordered_reshape$lrank - new_user_by_city_date_ordered_reshape$rank
symrankchange = ifelse(is.na(rankchange)|rankchange==0,"",ifelse(rankchange>0,intToUtf8(9650),intToUtf8(9660)))
sym = paste0(rankchange,symrankchange)
new_user_by_city_date_ordered_reshape$lsum = NULL
new_user_by_city_date_ordered_reshape$lrank = NULL
new_user_by_city_date_ordered_reshape = cbind(sym,new_user_by_city_date_ordered_reshape)
rownames(new_user_by_city_date_ordered_reshape) = 1:nrow(new_user_by_city_date_ordered_reshape)
DT::datatable(new_user_by_city_date_ordered_reshape, options = list(pageLength = 20))
channel_sql = paste0("select * from dl.dl_channel_umid_openid where substr(umid_firstonlinetime,1,10) >= '",as.character(datestart),"' and dt = ",dateend.str)
new_user_channel_unique = read_data_impala_general(channel_sql)
colnames(new_user_channel_unique) = str_replace(colnames(new_user_channel_unique),"dl_channel_umid_openid.","")
new_user_channel_unique = data.table(new_user_channel_unique)
new_user_channel_unique$date = str_sub(new_user_channel_unique$umid_firstonlinetime,1,10)
new_user_by_channel_date = new_user_channel_unique[,.(numbers = .N),by = c("channel","date")]
new_user_by_channel = new_user_channel_unique[,.(numbers = .N),by = c("channel")][order(numbers,decreasing = T)]
channel_list = new_user_by_channel$channel
new_user_by_channel_date_top = new_user_by_channel_date
new_user_by_channel_date_top$channels = factor(new_user_by_channel_date_top$channel,levels = channel_list)
new_user_by_channel_date_top_ordered = new_user_by_channel_date_top[order(date,channels)]
new_user_by_channel_date_ordered_reshape = dcast(new_user_by_channel_date_top_ordered, channels ~ date, value.var = "numbers")
new_user_by_channel_date_ordered_reshape$sum = rowSums(new_user_by_channel_date_ordered_reshape[,c(-1)],na.rm = T)
DT::datatable(new_user_by_channel_date_ordered_reshape, options = list(pageLength = 20))
#kable(channel,format = "markdown")
online_order_sql = paste0("select count(distinct purchaser_id) as o_num,substr(b.create_date,1,10) as dt from
(select purchaser_id,create_date from ods.ods_tx_order_tx_order_dt o inner join ods.ods_app_pageview_info a on
o.purchaser_id = a.u_id where substr(o.create_date,1,10)>= '",datestart,"' and o.order_status not in (1,7,19) and o.order_type=1) b
group by substr(b.create_date,1,10) order by substr(b.create_date,1,10)")
online_order = read_data_impala_general(online_order_sql)
total_order_sql = paste0("select count(distinct purchaser_id) as t_num,substr(b.create_date,1,10) as dt from
(select purchaser_id,create_date from ods.ods_tx_order_tx_order_dt o where substr(o.create_date,1,10)>= '",datestart,"' and o.order_status not in (1,7,19) and o.order_type=1) b
group by substr(b.create_date,1,10) order by substr(b.create_date,1,10)")
total_order = read_data_impala_general(total_order_sql)
matrix = as.matrix(cbind(online_num = online_order$o_num,total_num = total_order$t_num))
matrix = t(matrix)
par(bg = 'white')
colors <- c("blue","purple")
dates <- online_order$dt
stacks <- c("有过APP活动订单数","总订单数")
# Create the bar chart.
barplot(matrix,main="每日订单数",names.arg=dates,xlab="month",ylab="订单数",col=colors,beside = TRUE)
# Add the legend to the chart.
legend("topright",stacks, cex=0.7, fill=colors,xjust = 0, yjust = 1)
online_book_sql = paste0("select substr(d.create_date,1,10) dt,count(distinct d.openid) b_num from (select b.create_date,c.openid from
ods.ods_jz_business_jz_activity_user_dt b inner join
ods.ods_db_user_center_users_dt c on b.user_mobile=c.mobile
where b.is_del=0 and substr(create_date,1,10)>='",datestart,"') d
group by substr(d.create_date,1,10) order by substr(d.create_date,1,10)")
online_book = read_data_impala_general(online_book_sql)
barplot(online_book$b_num,names.arg = online_book$dt,col = "brown",xlab = "month",ylab = "预约数",main = "每日家装预约")
coupon_sql = paste0("select substr(d.create_time,1,10) dt,count(distinct d.open_id) c_num
from (select create_time,open_id from ods.ods_marketing_center_mmc_user_coupon_dt where
to_date(create_time)>='",datestart,"'
and channel_id not in (2,4) and open_id!='') d
group by substr(d.create_time,1,10) order by substr(d.create_time,1,10)")
coupon = read_data_impala_general(coupon_sql)
barplot(coupon$c_num,names.arg = coupon$dt,xlab = "month",ylab = "领券数",main = "每日领券情况",col = "blue")
dbDisconnect(con)
dbDisconnect(conn)
dbDisconnect(con)
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
Sys.setlocale(category = "LC_ALL", locale = "English_United States.1252")
pm <- ggplot(wpvuv, aes(as.Date(dt,format = "%Y%m%d"), pv)) + labs(x = "DATE",y = "PV") + ylim(0,max(wpvuv$pv,na.rm = T))
mainplot <- pm + geom_line(colour = I("purple")) + labs(title = "pv trend compare to last 1 month")+scale_x_date(labels = date_format("%m-%d"),date_breaks = "3 days")
# p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv))+labs(x = "DATE",y = "PV") + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))
p = ggplot(mpvuv,aes(as.Date(dt,format = "%Y%m%d"), pv)) + ylim(min(mpvuv$pv,na.rm = T),max(mpvuv$pv,na.rm = T))+scale_x_date(labels = date_format("%m-%d"),date_breaks = "10 days")+theme(axis.title = element_blank())
p1 <- p + geom_rect(aes(xmin = as.Date(mpvuv$dt[xmid],format = "%Y%m%d"), xmax = as.Date(mpvuv$dt[xlarge],format = "%Y%m%d"),
ymin = min(mpvuv$pv, na.rm = TRUE), ymax = max(mpvuv$pv, na.rm = TRUE)),fill = alpha("lightblue", 0.2))
subplot <- p1 + geom_line(colour = I("grey"),size = 0.8)
# vp <- viewport(width = 0.4, height = 0.4, x = 1,
#                y = unit(0.7, "lines"), just = c("right","bottom"))
vp <- viewport(width = 0.6, height = 0.4, x = 0.75,
y = 0.49, just = c("right","bottom"))
full <- function() {
print(mainplot)
print(subplot, vp = vp)
}
full()
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
Sys.setlocale(category = "LC_ALL", locale = "")
time_span_sql = paste0("select dt,
avg(persvg) totalavg,
avg(case when isnew ='new' then persvg else null end) newavg,
avg(case when isnew ='old' then persvg else null end) oldavg
from
(
select a.dt,a.u_mid,
sum(CAST(p_stay_time AS INT))/1000/60 persvg,
case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end isnew
from
ods.ods_app_pageview_info a
left outer join
dl.umid_firstonlinetime b on a.u_mid=b.u_mid
where a.dt>=",datestart.str," and b.dt='",dateend.str,"' and
p_domain='mmall.com' and service like '%staytime%' and substr(a.u_mid,1,2)!='a_' and path='z'  and l_city!='测试'
and p_type not in ('page.closedown','page.wakeup','page.activate.main') and length(p_stay_time)<=7
group by a.dt,a.u_mid,case when regexp_replace(to_date(firstonlinetime),'-','')=CAST(a.dt AS STRING) then 'new' else 'old' end
)a group by dt")
time_span = read_data_impala_general(time_span_sql)
time_span = time_span[order(time_span$dt),]
# write.xlsx(time_span,"~/data/uc_analysis/time_span.xlsx")
time_span$fdt = as.factor(time_span$dt)
time_span.new = time_span[,-1]
timespan.m <- melt(time_span.new)
timespan.m <- ddply(timespan.m, .(variable), transform,rescale = rescale(value))
timespan.m$dates = str_sub(as.character(timespan.m$fdt),5,8)
timespan.m$dates = factor(timespan.m$dates, levels = timespan.m$dates)
names(timespan.m) = c("fdt","old_new_user","time_span","rescale","dates")
# (p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple"))
p <- ggplot(timespan.m, aes(dates,old_new_user)) + geom_tile(aes(fill = time_span),colour = "white") + scale_fill_gradient(low = "white",high = "purple")
df = as.data.frame(t(time_span.new))
colnames(df) = time_span.new$fdt
df = df[-nrow(df),]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tbl1 <- tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tbl2 <- tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
# Plot chart and table into one object
grid.arrange(p, tbl1,tbl2,nrow=3,as.table=TRUE
# ,heights=c(3,1)
)
# plot_grid(p, tbl1, tbl2, align = "v", nrow = 3, rel_heights = c(1/2, 1/4, 1/4))
# rownames(time_span.new) = time_span.new$fdt
# DT::datatable(time_span.new[,-ncol(time_span.new)])
pvuv[pvuv$uv>1.3*meany,"dt"]
ifelse(length(abnormalhighdt)==0,"并没有哪天",abnormalhighdt)
abnormalhighdt
length(abnormalhighdt)==0
ifelse(c(FALSE,FALSE),"并没有哪天",abnormalhighdt)
`r if(length(abnormalhighdt)==0){"并没有哪天"} else{abnormalhighdt}``
``
`r if(length(abnormalhighdt)==0){"并没有哪天"} else{abnormalhighdt}`
if(length(abnormalhighdt)==0){"并没有哪天"} else{abnormalhighdt}
`r if(length(abnormalhighdt)==0){"并没有哪天"} else{abnormalhighdt}` 用户UV明显高于平均值
`r ifelse(length(abnormallowdt)==0,"并没有哪天",abnormallowdt)` 用户UV明显低于平均值
depth_p
depth_p_sql
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
p  = ggplot(depth_p,aes(fdt,avg_depth))
p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p_sql = paste0("select t.isnew,t.dt,sum(cast(u_depth as INT))/count(t.u_mid) avg_depth, count(t.u_mid) p_num from
(select a.dt,isnew,max(b.depth) as u_depth,a.u_mid from
dm.dm_app_umid_step a
left outer join
test.pagelevel2 b on a.page_name_zh=b.page_name where length(b.depth)=1 and a.dt > '",datestart.str,"' group by a.dt,a.isnew,a.u_mid) t group by t.isnew,t.dt")
depth_p = read_data_impala_general(depth_p_sql)
depth_p = depth_p[order(depth_p$dt),]
depth_p$fdt = factor(str_sub(depth_p$dt,5,8),levels = str_sub(depth_p$dt,5,8))
p  = ggplot(depth_p,aes(fdt,avg_depth))
p + geom_bar(aes(fill = isnew),stat = "identity",position = "dodge") + labs(x = "日期",y = "平均深度",title = "平均访问深度（按用户）")
depth_p$fdt = NULL
depth_p$value = round(depth_p$avg_depth,digits = 2)
df = dcast(depth_p[,-4],isnew~dt,value.var = "value")
rownames(df) = df[,1]
df = df[,-1]
tt <- ttheme_default(colhead=list(fg_params = list(parse=TRUE)))
tb1 = tableGrob(df[,1:round(ncol(df)/2)], rows=rownames(df), theme=tt)
tb2 = tableGrob(df[,(round(ncol(df)/2)+1):ncol(df)], rows=rownames(df), theme=tt)
grid.arrange(tb1,tb2,nrow = 2)
View(depth_p)
online_book_sql
knitr::opts_chunk$set(echo = FALSE)
library(readxl)
library(knitr)
library(xtable)
library(ggplot2)
library(reshape2)
library(scales)
library(plyr)
library(treemap)
library(grid)
library(gridExtra)
library(cowplot)
source('~/Rfile/R_impala.R')
# source('~/Rfile/R_hive.R')
datestart = Sys.Date()-14
dateend = Sys.Date()-1
datestart.str = format(datestart,'%Y%m%d')
dateend.str = format(dateend,'%Y%m%d')
dates = datestart.str:dateend.str
ldateend = Sys.Date()-15
ldatestart = Sys.Date()-28
ldatestart.str = format(ldatestart,'%Y%m%d')
ldateend.str = format(ldateend,'%Y%m%d')
options(scipen = 10)
survival_sql = paste0("select
a.dt,ndv(a.u_mid) t,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 then a.u_mid else null end)	t1,
ndv(if(a.isnew='new',a.u_mid,null)) newuv ,
ndv(case when datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1 and a.isnew='new' then a.u_mid else null end) newt1,
ndv(if(a.isnew='old',a.u_mid,null)) olduv,
ndv(case when  datediff(concat(substr(b.dt,1,4),'-',substr(b.dt,5,2),'-',substr(b.dt,7,2)),
concat(substr(a.dt,1,4),'-',substr(a.dt,5,2),'-',substr(a.dt,7,2)))=1  and a.isnew='old' then a.u_mid else null end) noldt1
from dl.umid_pv a
left outer join
dl.umid_pv b on a.u_mid=b.u_mid
where  a.dt>='",datestart.str,"' group by a.dt")
survival = read_data_impala_general(survival_sql)
# survival = read_data_hive_general(survival_sql)
survival = survival[order(survival$dt),]
survival = survival[-nrow(survival),]
survival$fdt = as.factor(survival$dt)
par(bg = 'black')
colors = rainbow(3)
#考虑survival,!!须注意最后一天
ylarge = max(max(survival$t1/survival$t),max(survival$newt1/survival$newuv),max(survival$noldt1/survival$olduv))
plot(as.numeric(survival$fdt),survival$t1/survival$t,col = colors[[1]],type = 'l',ylim = c(0,ceiling(ylarge)))
lines(as.numeric(survival$fdt),survival$newt1/survival$newuv,col = colors[[2]],type = 'l')
lines(as.numeric(survival$fdt),survival$noldt1/survival$olduv,col = colors[[3]], type = 'l')
legend('topright',c("survival","newsurvival","oldsurvival"),cex = 0.7,fill = colors,text.col= 'pink')
#需要加入坐标轴
title(main = '近两周次日留存率',xlab = 'dates',ylab = '留存率',col.main = 'blue',
col.lab = 'purple')
axis(1,col = 'purple')
at = str_sub(survival$dt,5,8)[seq(from = 2,to = 14,by = 2)]
mtext(side = 1, text = at, at = seq(from = 2,to = 14,by = 2), col = "purple", line = 1)
axis(2,col = 'purple')
at = axTicks(2)
mtext(side = 2,text = at,at = at,col = 'purple',line = 1)
